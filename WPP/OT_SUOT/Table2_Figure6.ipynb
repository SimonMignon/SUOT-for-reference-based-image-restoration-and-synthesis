{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c360349",
   "metadata": {},
   "source": [
    "# WPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7f7649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/WPP/OT_SUOT', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python37.zip', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/lib-dynload', '', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/IPython/extensions', '/home/prof/smignon/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "  \n",
    "# Prints the list of directories that the \n",
    "# interpreter will search for the required module. \n",
    "print(sys.path)\n",
    "\n",
    "sys.path.insert(0, \"/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5901fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code belongs to the paper\n",
    "#\n",
    "# J. Hertrich, A. Houdard and C. Redenbach.\n",
    "# Wasserstein Patch Prior for Image Superresolution.\n",
    "# IEEE Transactions on Computational Imaging, 2022.\n",
    "#\n",
    "# Please cite the paper, if you use this code.\n",
    "#\n",
    "# This script applies the Wasserstein Patch Prior reconstruction onto the 2D SiC Diamonds image\n",
    "# from Section 4.2 of the paper.\n",
    "#\n",
    "import argparse\n",
    "import wgenpatex_color as wgenpatex\n",
    "import torch\n",
    "import skimage.transform\n",
    "from skimage import (color, data, measure)\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import os\n",
    "import lpips\n",
    "import glob\n",
    "import torchvision\n",
    "from torchvision.transforms import Resize as tv_resize\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# images PATH\n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/Datasets/18_images_wd_wod_dataset')  \n",
    "\n",
    "list_im_name   = [file for file in glob.glob(\"HR/*.png\")]#.sort()\n",
    "list_im_modele_with_def   = [file for file in glob.glob(\"HR_wd/*.png\")]#.sort()\n",
    "list_im_modele_without_def   = [file for file in glob.glob(\"HR_wod/*.png\")]#.sort()\n",
    "\n",
    "list_im_name.sort()\n",
    "list_im_modele_with_def.sort()\n",
    "list_im_modele_without_def.sort()\n",
    "list_im_modele=[list_im_modele_with_def,list_im_modele_without_def]\n",
    "\n",
    "# Lists\n",
    "#PSNR \n",
    "def PSNR(im,im_new):\n",
    "    C,M,N=im_new.shape\n",
    "    EQM=1/(C*M*N)*torch.sum((im-im_new)**2)\n",
    "    psnr=10*torch.log10(1/EQM)\n",
    "    return(psnr)\n",
    "\n",
    "list_psnr_WPP=[[],[]]\n",
    "\n",
    "# restored images \n",
    "list_im_rest_WPP=[[],[]]\n",
    "\n",
    "# lr img\n",
    "list_im_LR=[[],[]]\n",
    "\n",
    "# LPIPS\n",
    "loss_fn_alex = lpips.LPIPS(net='alex')\n",
    "list_lpips_WPP=[[],[]]\n",
    "\n",
    "# SSIM\n",
    "list_ssim_WPP=[[],[]]\n",
    "\n",
    "for i,name_im in enumerate(list_im_name):\n",
    "    for j in range(2):\n",
    "        # set arguments\n",
    "        args=argparse.Namespace()\n",
    "        args.target_image_path=name_im\n",
    "        args.scales=2\n",
    "        args.keops=True\n",
    "        args.n_iter_max=500\n",
    "        args.save=True\n",
    "        args.n_patches_out=10000\n",
    "        args.learn_image_path=list_im_modele[j][i]\n",
    "        args.patch_size=6\n",
    "        args.lam=(6000/(3*args.patch_size**2))*(256**2/600**2)\n",
    "        args.n_iter_psi=10\n",
    "        args.n_patches_in=-1\n",
    "        args.visu=False\n",
    "\n",
    "\n",
    "        # define forward operator\n",
    "        blur_width=2.0\n",
    "        add_boundary=20\n",
    "        kernel_size=16\n",
    "        stride=4\n",
    "        my_layer=wgenpatex.gaussian_layer(kernel_size,blur_width,stride=stride)\n",
    "\n",
    "        def operator(inp):\n",
    "            if add_boundary==0:\n",
    "                return my_layer.forward(inp)\n",
    "            return my_layer.forward(inp[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary])\n",
    "        \n",
    "        torch.manual_seed(i) # reproductibilité de l'expérience\n",
    "        \n",
    "        # read HR ground truth\n",
    "        hr_img=wgenpatex.imread(args.target_image_path)\n",
    "        hr_img=tv_resize(256, antialias=True)(hr_img)\n",
    "\n",
    "        lr_img=wgenpatex.imread(args.target_image_path)\n",
    "        lr_img=tv_resize(256, antialias=True)(lr_img)\n",
    "        args.size=lr_img.shape[2:4]\n",
    "        lr_img_=np.zeros((3,lr_img.shape[2]+2*add_boundary,lr_img.shape[3]+2*add_boundary))\n",
    "        if add_boundary>0:\n",
    "            lr_img_[:,add_boundary:-add_boundary,add_boundary:-add_boundary]=lr_img.squeeze().cpu().numpy()\n",
    "        else:\n",
    "            lr_img_=lr_img.squeeze().cpu().numpy()\n",
    "\n",
    "        # create (artificially) LR observation\n",
    "        lr_img=operator(torch.tensor(lr_img_,dtype=torch.float,device=DEVICE).view(1,3,lr_img_.shape[1],lr_img_.shape[2]))\n",
    "        lr_img+=0.01*torch.randn_like(lr_img)\n",
    "        wgenpatex.imsave('input_imgs/lr_diam.png',lr_img)\n",
    "\n",
    "\n",
    "        # build initialization by rescaling the lr observation and extending it to the boundary\n",
    "        upscaled=skimage.transform.resize(lr_img.squeeze().cpu().numpy(),[3,lr_img.shape[2]*stride,lr_img.shape[3]*stride])\n",
    "        diff=args.size[0]-upscaled.shape[1]\n",
    "\n",
    "        init=np.zeros((3,args.size[0],args.size[1]),dtype=bool)\n",
    "        init[:,diff//2:-diff//2,diff//2:-diff//2]=True\n",
    "        grid_x=np.array(range(init.shape[1]))\n",
    "        grid_x=np.tile(grid_x[:,np.newaxis],[1,init.shape[2]])\n",
    "        grid_y=np.array(range(init.shape[2]))\n",
    "        grid_y=np.tile(grid_y[np.newaxis,:],[init.shape[1],1])\n",
    "        points_x=np.reshape(grid_x[init[0,:,:]],[-1])\n",
    "        points_y=np.reshape(grid_y[init[0,:,:]],[-1])\n",
    "        init=init.astype(float)\n",
    "        for k in range(3):\n",
    "            values=np.reshape(upscaled[k,:,:],[-1])\n",
    "            points=np.stack([points_x,points_y],0).transpose()\n",
    "            init[k,:,:]=griddata(points,values,(grid_x,grid_y),method='nearest')\n",
    "            \n",
    "        init_=np.random.uniform(size=(3,init.shape[1]+2*add_boundary,init.shape[2]+2*add_boundary))\n",
    "        if add_boundary==0:\n",
    "            init_=init\n",
    "        else:\n",
    "            init_[:,add_boundary:-add_boundary,add_boundary:-add_boundary]=init\n",
    "        args.size=init_.shape\n",
    "\n",
    "        # load learn img\n",
    "        learn_img=wgenpatex.imread(args.learn_image_path)\n",
    "        learn_img=tv_resize(256, antialias=True)(learn_img)\n",
    "        print(learn_img.dtype)\n",
    "\n",
    "        # run reconstruction\n",
    "        synth_img= wgenpatex.optim_synthesis_SR(args,operator,lr_img,learn_img,args.lam,init=init_,add_boundary=add_boundary)\n",
    "        \n",
    "        if add_boundary>0:\n",
    "            synth_img=synth_img[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary]\n",
    "\n",
    "        list_im_rest_WPP[j].append(synth_img)\n",
    "        # PSNR\n",
    "        list_psnr_WPP[j].append(PSNR(torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')),\n",
    "                                torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu'))))\n",
    "        # LPIPS\n",
    "        list_lpips_WPP[j].append(loss_fn_alex(torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')).unsqueeze(0)\n",
    "                                          , torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu')).unsqueeze(0)))\n",
    "        \n",
    "        # SSIM\n",
    "        img_hr=torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')).detach().numpy().transpose(1, 2, 0)\n",
    "        img_pred_WPP=torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu')).detach().numpy().transpose(1, 2, 0)\n",
    "        list_ssim_WPP[j].append(ssim(img_hr, img_pred_WPP,data_range=img_pred_WPP.max() - img_pred_WPP.min(),multichannel=True))\n",
    "        print(i)\n",
    "        \n",
    "        #wgenpatex.imsave('output_imgs_diam/synthesized_with_bound.png', synth_img)\n",
    "\n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/WPP/OT_SUOT') \n",
    "torch.save(list_psnr_WPPSU,\"list_psnr_WPP_color\")\n",
    "torch.save(list_lpips_WPPSU,\"list_lpips_WPP_color\")\n",
    "torch.save(list_ssim_WPPSU,\"list_ssim_WPP_color\")\n",
    "torch.save(list_im_rest_WPPSU,\"list_im_rest_WPP_color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaee4e3",
   "metadata": {},
   "source": [
    "# WPPSU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93924d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code belongs to the paper\n",
    "#\n",
    "# J. Hertrich, A. Houdard and C. Redenbach.\n",
    "# Wasserstein Patch Prior for Image Superresolution.\n",
    "# IEEE Transactions on Computational Imaging, 2022.\n",
    "#\n",
    "# Please cite the paper, if you use this code.\n",
    "#\n",
    "# This script applies the Wasserstein Patch Prior reconstruction onto the 2D SiC Diamonds image\n",
    "# from Section 4.2 of the paper.\n",
    "#\n",
    "import argparse\n",
    "import wgenpatex_color_SU as wgenpatex\n",
    "import torch\n",
    "import skimage.transform\n",
    "from skimage import (color, data, measure)\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import os\n",
    "import lpips\n",
    "import glob\n",
    "import torchvision\n",
    "from torchvision.transforms import Resize as tv_resize\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "torch.cuda.set_device(2)\n",
    "\n",
    "# images PATH\n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/Datasets/18_images_wd_wod_dataset')  \n",
    " \n",
    "list_im_name   = [file for file in glob.glob(\"HR/*.png\")]#.sort()\n",
    "list_im_modele_with_def   = [file for file in glob.glob(\"HR_wd/*.png\")]#.sort()\n",
    "list_im_modele_without_def   = [file for file in glob.glob(\"HR_wod/*.png\")]#.sort()\n",
    "\n",
    "list_im_name.sort()\n",
    "list_im_modele_with_def.sort()\n",
    "list_im_modele_without_def.sort()\n",
    "list_im_modele=[list_im_modele_with_def,list_im_modele_without_def]\n",
    "\n",
    "# Lists\n",
    "#PSNR \n",
    "def PSNR(im,im_new):\n",
    "    C,M,N=im_new.shape\n",
    "    EQM=1/(C*M*N)*torch.sum((im-im_new)**2)\n",
    "    psnr=10*torch.log10(1/EQM)\n",
    "    return(psnr)\n",
    "\n",
    "list_psnr_WPPSU=[[],[]]\n",
    "\n",
    "# restored images \n",
    "list_im_rest_WPPSU=[[],[]]\n",
    "\n",
    "# lr img\n",
    "list_im_LR=[[],[]]\n",
    "\n",
    "# LPIPS\n",
    "loss_fn_alex = lpips.LPIPS(net='alex')\n",
    "list_lpips_WPPSU=[[],[]]\n",
    "\n",
    "# SSIM\n",
    "list_ssim_WPPSU=[[],[]]\n",
    "\n",
    "# SSIM\n",
    "list_ssim_WPPSU=[[],[]]\n",
    "for i,name_im in enumerate(list_im_name):\n",
    "    for j in range(2):\n",
    "        # set arguments\n",
    "        args=argparse.Namespace()\n",
    "        args.target_image_path=name_im\n",
    "        args.scales=2\n",
    "        args.keops=True\n",
    "        args.n_iter_max=500\n",
    "        args.save=True\n",
    "        args.n_patches_out=10000\n",
    "        args.learn_image_path=list_im_modele[j][i]\n",
    "        args.patch_size=6\n",
    "        args.lam=(6000/(3*args.patch_size**2))*(256**2/600**2)\n",
    "        args.n_iter_psi=10\n",
    "        args.n_patches_in=-1\n",
    "        args.visu=False\n",
    "\n",
    "\n",
    "        # define forward operator\n",
    "        blur_width=2.0\n",
    "        add_boundary=0\n",
    "        kernel_size=16\n",
    "        stride=4\n",
    "        my_layer=wgenpatex.gaussian_layer(kernel_size,blur_width,stride=stride)\n",
    "\n",
    "        def operator(inp):\n",
    "            if add_boundary==0:\n",
    "                return my_layer.forward(inp)\n",
    "            return my_layer.forward(inp[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary])\n",
    "        \n",
    "        torch.manual_seed(i) # reproductibilité de l'expérience\n",
    "        \n",
    "        # read HR ground truth\n",
    "        hr_img=wgenpatex.imread(args.target_image_path)\n",
    "        hr_img=tv_resize(256, antialias=True)(hr_img)\n",
    "\n",
    "        lr_img=wgenpatex.imread(args.target_image_path)\n",
    "        lr_img=tv_resize(256, antialias=True)(lr_img)\n",
    "        args.size=lr_img.shape[2:4]\n",
    "        lr_img_=np.zeros((3,lr_img.shape[2]+2*add_boundary,lr_img.shape[3]+2*add_boundary))\n",
    "        if add_boundary>0:\n",
    "            lr_img_[:,add_boundary:-add_boundary,add_boundary:-add_boundary]=lr_img.squeeze().cpu().numpy()\n",
    "        else:\n",
    "            lr_img_=lr_img.squeeze().cpu().numpy()\n",
    "\n",
    "        # create (artificially) LR observation\n",
    "        lr_img=operator(torch.tensor(lr_img_,dtype=torch.float,device=DEVICE).view(1,3,lr_img_.shape[1],lr_img_.shape[2]))\n",
    "        lr_img+=0.01*torch.randn_like(lr_img)\n",
    "        \n",
    "\n",
    "\n",
    "        # build initialization by rescaling the lr observation and extending it to the boundary\n",
    "        upscaled=skimage.transform.resize(lr_img.squeeze().cpu().numpy(),[3,lr_img.shape[2]*stride,lr_img.shape[3]*stride])\n",
    "        diff=args.size[0]-upscaled.shape[1]\n",
    "\n",
    "        init=np.zeros((3,args.size[0],args.size[1]),dtype=bool)\n",
    "        init[:,diff//2:-diff//2,diff//2:-diff//2]=True\n",
    "        grid_x=np.array(range(init.shape[1]))\n",
    "        grid_x=np.tile(grid_x[:,np.newaxis],[1,init.shape[2]])\n",
    "        grid_y=np.array(range(init.shape[2]))\n",
    "        grid_y=np.tile(grid_y[np.newaxis,:],[init.shape[1],1])\n",
    "        points_x=np.reshape(grid_x[init[0,:,:]],[-1])\n",
    "        points_y=np.reshape(grid_y[init[0,:,:]],[-1])\n",
    "        init=init.astype(float)\n",
    "        for k in range(3):\n",
    "            values=np.reshape(upscaled[k,:,:],[-1])\n",
    "            points=np.stack([points_x,points_y],0).transpose()\n",
    "            init[k,:,:]=griddata(points,values,(grid_x,grid_y),method='nearest')\n",
    "            #print(init.shape)\n",
    "        init_=np.random.uniform(size=(3,init.shape[1]+2*add_boundary,init.shape[2]+2*add_boundary))\n",
    "        if add_boundary==0:\n",
    "            init_=init\n",
    "        else:\n",
    "            init_[:,add_boundary:-add_boundary,add_boundary:-add_boundary]=init\n",
    "        args.size=init_.shape\n",
    "\n",
    "        # load learn img\n",
    "        learn_img=wgenpatex.imread(args.learn_image_path)\n",
    "        learn_img=tv_resize(256, antialias=True)(learn_img)\n",
    "        print(learn_img.dtype)\n",
    "\n",
    "       # run reconstruction\n",
    "        synth_img= wgenpatex.optim_synthesis_SR(args,operator,lr_img,learn_img,args.lam,ρ=0.01,init=init_,add_boundary=add_boundary)\n",
    "\n",
    "        # save reconstruction\n",
    "        #if not os.path.isdir('output_imgs_diam'):\n",
    "            #os.mkdir('output_imgs_diam')\n",
    "\n",
    "        #wgenpatex.imsave('output_imgs_diam/synthesized_no_crop_bound.png', synth_img)\n",
    "        if add_boundary>0:\n",
    "            synth_img=synth_img[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary]\n",
    "        # Restored image \n",
    "        list_im_rest_WPPSU[j].append(synth_img)\n",
    "        # PSNR\n",
    "        list_psnr_WPPSU[j].append(PSNR(torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')),\n",
    "                                torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu'))))\n",
    "        # LPIPS\n",
    "        list_lpips_WPPSU[j].append(loss_fn_alex(torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')).unsqueeze(0)\n",
    "                                          , torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu')).unsqueeze(0)))\n",
    "        \n",
    "        # SSIM\n",
    "        img_hr=torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')).detach().numpy().transpose(1, 2, 0)\n",
    "        img_pred_WPPSU=torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu')).detach().numpy().transpose(1, 2, 0)\n",
    "        list_ssim_WPPSU[j].append(ssim(img_hr, img_pred_WPPSU,data_range=img_pred_WPPSU.max() - img_pred_WPPSU.min(),multichannel=True))\n",
    "        print(i)\n",
    "\n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/WPP/OT_SUOT')\n",
    "torch.save(list_psnr_WPPSU,\"list_psnr_WPPSU_color\")\n",
    "torch.save(list_lpips_WPPSU,\"list_lpips_WPPSU_color\")\n",
    "torch.save(list_ssim_WPPSU,\"list_ssim_WPPSU_color\")\n",
    "torch.save(list_im_rest_WPPSU,\"list_im_rest_WPPSU_color\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WPP_color",
   "language": "python",
   "name": "wpp_color"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
