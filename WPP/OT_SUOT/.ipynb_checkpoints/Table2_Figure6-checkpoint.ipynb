{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c360349",
   "metadata": {},
   "source": [
    "# WPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb7f7649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/WPP/OT_SUOT', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python37.zip', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/lib-dynload', '', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/IPython/extensions', '/home/prof/smignon/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "  \n",
    "# Prints the list of directories that the \n",
    "# interpreter will search for the required module. \n",
    "print(sys.path)\n",
    "\n",
    "sys.path.insert(0, \"/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5901fdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/lpips/weights/v0.1/alex.pth\n",
      "torch.float32\n",
      "iteration 0 - elapsed 2s - loss = 1.7010601460933685\n",
      "iteration 50 - elapsed 27s - loss = 0.16055934876203537\n",
      "iteration 100 - elapsed 53s - loss = 0.10671623796224594\n",
      "iteration 150 - elapsed 79s - loss = 0.11182770598679781\n",
      "iteration 200 - elapsed 105s - loss = 0.11609230376780033\n",
      "iteration 250 - elapsed 132s - loss = 0.11927298456430435\n",
      "iteration 300 - elapsed 158s - loss = 0.12256767321377993\n",
      "iteration 350 - elapsed 185s - loss = 0.12541600223630667\n",
      "iteration 400 - elapsed 212s - loss = 0.12815236300230026\n",
      "iteration 450 - elapsed 239s - loss = 0.13089385628700256\n",
      "DONE - total time is 265s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.float32\n",
      "iteration 0 - elapsed 0s - loss = 1.813114732503891\n",
      "iteration 50 - elapsed 25s - loss = 0.1541540939360857\n",
      "iteration 100 - elapsed 51s - loss = 0.08210498373955488\n",
      "iteration 150 - elapsed 77s - loss = 0.0814661243930459\n",
      "iteration 200 - elapsed 104s - loss = 0.08433889597654343\n",
      "iteration 250 - elapsed 130s - loss = 0.08783263806253672\n",
      "iteration 300 - elapsed 157s - loss = 0.09105996135622263\n",
      "iteration 350 - elapsed 184s - loss = 0.093702451325953\n",
      "iteration 400 - elapsed 211s - loss = 0.09561012964695692\n",
      "iteration 450 - elapsed 237s - loss = 0.0973976356908679\n",
      "DONE - total time is 255s\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# This code belongs to the paper\n",
    "#\n",
    "# J. Hertrich, A. Houdard and C. Redenbach.\n",
    "# Wasserstein Patch Prior for Image Superresolution.\n",
    "# IEEE Transactions on Computational Imaging, 2022.\n",
    "#\n",
    "# Please cite the paper, if you use this code.\n",
    "#\n",
    "# This script applies the Wasserstein Patch Prior reconstruction onto the 2D SiC Diamonds image\n",
    "# from Section 4.2 of the paper.\n",
    "#\n",
    "import argparse\n",
    "import wgenpatex_color as wgenpatex\n",
    "import torch\n",
    "import skimage.transform\n",
    "from skimage import (color, data, measure)\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import os\n",
    "import lpips\n",
    "import glob\n",
    "import torchvision\n",
    "from torchvision.transforms import Resize as tv_resize\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "torch.cuda.set_device(2)\n",
    "\n",
    "# images PATH\n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/Datasets/18_images_wa_woa_dataset')  \n",
    "\n",
    "list_im_name   = [file for file in glob.glob(\"HR/*.png\")]#.sort()\n",
    "list_im_modele_with_a   = [file for file in glob.glob(\"HR_with_anomalies/*.png\")]#.sort()\n",
    "list_im_modele_without_a   = [file for file in glob.glob(\"HR_without_anomalies/*.png\")]#.sort()\n",
    "\n",
    "list_im_name.sort()\n",
    "list_im_modele_with_a.sort()\n",
    "list_im_modele_without_a.sort()\n",
    "list_im_modele=[list_im_modele_with_a,list_im_modele_without_a]\n",
    "\n",
    "# Lists\n",
    "#PSNR \n",
    "def PSNR(im,im_new):\n",
    "    C,M,N=im_new.shape\n",
    "    EQM=1/(C*M*N)*torch.sum((im-im_new)**2)\n",
    "    psnr=10*torch.log10(1/EQM)\n",
    "    return(psnr)\n",
    "\n",
    "list_psnr_WPP=[[],[]]\n",
    "\n",
    "# restored images \n",
    "list_im_rest_WPP=[[],[]]\n",
    "\n",
    "# lr img\n",
    "list_im_LR=[[],[]]\n",
    "\n",
    "# LPIPS\n",
    "loss_fn_alex = lpips.LPIPS(net='alex')\n",
    "list_lpips_WPP=[[],[]]\n",
    "\n",
    "# SSIM\n",
    "list_ssim_WPP=[[],[]]\n",
    "\n",
    "# for i,name_im in enumerate(list_im_name): # RUN ALL IMAGES \n",
    "for i,name_im in enumerate([list_im_name[0]]): # TEST ON SINGLE IMAGE\n",
    "    for j in range(2):\n",
    "        # set arguments\n",
    "        args=argparse.Namespace()\n",
    "        args.target_image_path=name_im\n",
    "        args.scales=2\n",
    "        args.keops=True\n",
    "        args.n_iter_max=500\n",
    "        args.save=True\n",
    "        args.n_patches_out=10000\n",
    "        args.learn_image_path=list_im_modele[j][i]\n",
    "        args.patch_size=6\n",
    "        args.lam=(6000/(3*args.patch_size**2))*(256**2/600**2)\n",
    "        args.n_iter_psi=10\n",
    "        args.n_patches_in=-1\n",
    "        args.visu=False\n",
    "\n",
    "\n",
    "        # define forward operator\n",
    "        blur_width=2.0\n",
    "        add_boundary=20\n",
    "        kernel_size=16\n",
    "        stride=4\n",
    "        my_layer=wgenpatex.gaussian_layer(kernel_size,blur_width,stride=stride)\n",
    "\n",
    "        def operator(inp):\n",
    "            if add_boundary==0:\n",
    "                return my_layer.forward(inp)\n",
    "            return my_layer.forward(inp[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary])\n",
    "        \n",
    "        torch.manual_seed(i) # reproductibilité de l'expérience\n",
    "        \n",
    "        # read HR ground truth\n",
    "        hr_img=wgenpatex.imread(args.target_image_path)\n",
    "        hr_img=tv_resize(256, antialias=True)(hr_img)\n",
    "\n",
    "        lr_img=wgenpatex.imread(args.target_image_path)\n",
    "        lr_img=tv_resize(256, antialias=True)(lr_img)\n",
    "        args.size=lr_img.shape[2:4]\n",
    "        lr_img_=np.zeros((3,lr_img.shape[2]+2*add_boundary,lr_img.shape[3]+2*add_boundary))\n",
    "        if add_boundary>0:\n",
    "            lr_img_[:,add_boundary:-add_boundary,add_boundary:-add_boundary]=lr_img.squeeze().cpu().numpy()\n",
    "        else:\n",
    "            lr_img_=lr_img.squeeze().cpu().numpy()\n",
    "\n",
    "        # create (artificially) LR observation\n",
    "        lr_img=operator(torch.tensor(lr_img_,dtype=torch.float,device=DEVICE).view(1,3,lr_img_.shape[1],lr_img_.shape[2]))\n",
    "        lr_img+=0.01*torch.randn_like(lr_img)\n",
    "\n",
    "\n",
    "        # build initialization by rescaling the lr observation and extending it to the boundary\n",
    "        upscaled=skimage.transform.resize(lr_img.squeeze().cpu().numpy(),[3,lr_img.shape[2]*stride,lr_img.shape[3]*stride])\n",
    "        diff=args.size[0]-upscaled.shape[1]\n",
    "\n",
    "        init=np.zeros((3,args.size[0],args.size[1]),dtype=bool)\n",
    "        init[:,diff//2:-diff//2,diff//2:-diff//2]=True\n",
    "        grid_x=np.array(range(init.shape[1]))\n",
    "        grid_x=np.tile(grid_x[:,np.newaxis],[1,init.shape[2]])\n",
    "        grid_y=np.array(range(init.shape[2]))\n",
    "        grid_y=np.tile(grid_y[np.newaxis,:],[init.shape[1],1])\n",
    "        points_x=np.reshape(grid_x[init[0,:,:]],[-1])\n",
    "        points_y=np.reshape(grid_y[init[0,:,:]],[-1])\n",
    "        init=init.astype(float)\n",
    "        for k in range(3):\n",
    "            values=np.reshape(upscaled[k,:,:],[-1])\n",
    "            points=np.stack([points_x,points_y],0).transpose()\n",
    "            init[k,:,:]=griddata(points,values,(grid_x,grid_y),method='nearest')\n",
    "            \n",
    "        init_=np.random.uniform(size=(3,init.shape[1]+2*add_boundary,init.shape[2]+2*add_boundary))\n",
    "        if add_boundary==0:\n",
    "            init_=init\n",
    "        else:\n",
    "            init_[:,add_boundary:-add_boundary,add_boundary:-add_boundary]=init\n",
    "        args.size=init_.shape\n",
    "\n",
    "        # load learn img\n",
    "        learn_img=wgenpatex.imread(args.learn_image_path)\n",
    "        learn_img=tv_resize(256, antialias=True)(learn_img)\n",
    "        print(learn_img.dtype)\n",
    "\n",
    "        # run reconstruction\n",
    "        synth_img= wgenpatex.optim_synthesis_SR(args,operator,lr_img,learn_img,args.lam,init=init_,add_boundary=add_boundary)\n",
    "        \n",
    "        if add_boundary>0:\n",
    "            synth_img=synth_img[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary]\n",
    "\n",
    "        list_im_rest_WPP[j].append(synth_img)\n",
    "        # PSNR\n",
    "        list_psnr_WPP[j].append(PSNR(torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')),\n",
    "                                torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu'))))\n",
    "        # LPIPS\n",
    "        list_lpips_WPP[j].append(loss_fn_alex(torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')).unsqueeze(0)\n",
    "                                          , torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu')).unsqueeze(0)))\n",
    "        \n",
    "        # SSIM\n",
    "        img_hr=torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')).detach().numpy().transpose(1, 2, 0)\n",
    "        img_pred_WPP=torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu')).detach().numpy().transpose(1, 2, 0)\n",
    "        list_ssim_WPP[j].append(ssim(img_hr, img_pred_WPP,data_range=img_pred_WPP.max() - img_pred_WPP.min(),multichannel=True))\n",
    "        print(i)\n",
    "        \n",
    "        #wgenpatex.imsave('output_imgs_diam/synthesized_with_bound.png', synth_img)\n",
    "\n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/WPP/OT_SUOT') \n",
    "torch.save(list_psnr_WPP,\"list_psnr_WPP_color\")\n",
    "torch.save(list_lpips_WPP,\"list_lpips_WPP_color\")\n",
    "torch.save(list_ssim_WPP,\"list_ssim_WPP_color\")\n",
    "torch.save(list_im_rest_WPP,\"list_im_rest_WPP_color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaee4e3",
   "metadata": {},
   "source": [
    "# WPPSU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93924d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/lpips/weights/v0.1/alex.pth\n",
      "torch.float32\n",
      "iteration 0 - elapsed 1s - loss = 0.45976512506604195\n",
      "iteration 50 - elapsed 23s - loss = 0.06566169019788504\n",
      "iteration 100 - elapsed 44s - loss = 0.06556749250739813\n",
      "iteration 150 - elapsed 66s - loss = 0.06591822300106287\n",
      "iteration 200 - elapsed 87s - loss = 0.06607427354902029\n",
      "iteration 250 - elapsed 109s - loss = 0.06619521789252758\n",
      "iteration 300 - elapsed 131s - loss = 0.06629220396280289\n",
      "iteration 350 - elapsed 152s - loss = 0.06636372581124306\n",
      "iteration 400 - elapsed 173s - loss = 0.0664227232336998\n",
      "iteration 450 - elapsed 195s - loss = 0.06646533124148846\n",
      "DONE - total time is 216s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.float32\n",
      "iteration 0 - elapsed 0s - loss = 0.46226460114121437\n",
      "iteration 50 - elapsed 22s - loss = 0.053009345196187496\n",
      "iteration 100 - elapsed 43s - loss = 0.052411168813705444\n",
      "iteration 150 - elapsed 65s - loss = 0.05260974634438753\n",
      "iteration 200 - elapsed 86s - loss = 0.05266841221600771\n",
      "iteration 250 - elapsed 104s - loss = 0.052698975428938866\n",
      "iteration 300 - elapsed 121s - loss = 0.052756570279598236\n",
      "iteration 350 - elapsed 152s - loss = 0.0527811162173748\n",
      "iteration 400 - elapsed 187s - loss = 0.05277923494577408\n",
      "iteration 450 - elapsed 222s - loss = 0.052807172760367393\n",
      "DONE - total time is 256s\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# This code belongs to the paper\n",
    "#\n",
    "# J. Hertrich, A. Houdard and C. Redenbach.\n",
    "# Wasserstein Patch Prior for Image Superresolution.\n",
    "# IEEE Transactions on Computational Imaging, 2022.\n",
    "#\n",
    "# Please cite the paper, if you use this code.\n",
    "#\n",
    "# This script applies the Wasserstein Patch Prior reconstruction onto the 2D SiC Diamonds image\n",
    "# from Section 4.2 of the paper.\n",
    "#\n",
    "import argparse\n",
    "import wgenpatex_color_SU as wgenpatex\n",
    "import torch\n",
    "import skimage.transform\n",
    "from skimage import (color, data, measure)\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import os\n",
    "import lpips\n",
    "import glob\n",
    "import torchvision\n",
    "from torchvision.transforms import Resize as tv_resize\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "torch.cuda.set_device(2)\n",
    "\n",
    "# images PATH\n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/Datasets/18_images_wa_woa_dataset')  \n",
    "\n",
    "list_im_name   = [file for file in glob.glob(\"HR/*.png\")]#.sort()\n",
    "list_im_modele_with_a   = [file for file in glob.glob(\"HR_with_anomalies/*.png\")]#.sort()\n",
    "list_im_modele_without_a   = [file for file in glob.glob(\"HR_without_anomalies/*.png\")]#.sort()\n",
    "\n",
    "list_im_name.sort()\n",
    "list_im_modele_with_a.sort()\n",
    "list_im_modele_without_a.sort()\n",
    "list_im_modele=[list_im_modele_with_a,list_im_modele_without_a]\n",
    "\n",
    "# Lists\n",
    "#PSNR \n",
    "def PSNR(im,im_new):\n",
    "    C,M,N=im_new.shape\n",
    "    EQM=1/(C*M*N)*torch.sum((im-im_new)**2)\n",
    "    psnr=10*torch.log10(1/EQM)\n",
    "    return(psnr)\n",
    "\n",
    "list_psnr_WPPSU=[[],[]]\n",
    "\n",
    "# restored images \n",
    "list_im_rest_WPPSU=[[],[]]\n",
    "\n",
    "# lr img\n",
    "list_im_LR=[[],[]]\n",
    "\n",
    "# LPIPS\n",
    "loss_fn_alex = lpips.LPIPS(net='alex')\n",
    "list_lpips_WPPSU=[[],[]]\n",
    "\n",
    "# SSIM\n",
    "list_ssim_WPPSU=[[],[]]\n",
    "\n",
    "# SSIM\n",
    "list_ssim_WPPSU=[[],[]]\n",
    "# for i,name_im in enumerate(list_im_name): # RUN ALL IMAGES \n",
    "for i,name_im in enumerate([list_im_name[0]]): # TEST ON SINGLE IMAGE\n",
    "    for j in range(2):\n",
    "        # set arguments\n",
    "        args=argparse.Namespace()\n",
    "        args.target_image_path=name_im\n",
    "        args.scales=2\n",
    "        args.keops=True\n",
    "        args.n_iter_max=500\n",
    "        args.save=True\n",
    "        args.n_patches_out=10000\n",
    "        args.learn_image_path=list_im_modele[j][i]\n",
    "        args.patch_size=6\n",
    "        args.lam=(6000/(3*args.patch_size**2))*(256**2/600**2)\n",
    "        args.n_iter_psi=10\n",
    "        args.n_patches_in=-1\n",
    "        args.visu=False\n",
    "\n",
    "\n",
    "        # define forward operator\n",
    "        blur_width=2.0\n",
    "        add_boundary=0\n",
    "        kernel_size=16\n",
    "        stride=4\n",
    "        my_layer=wgenpatex.gaussian_layer(kernel_size,blur_width,stride=stride)\n",
    "\n",
    "        def operator(inp):\n",
    "            if add_boundary==0:\n",
    "                return my_layer.forward(inp)\n",
    "            return my_layer.forward(inp[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary])\n",
    "        \n",
    "        torch.manual_seed(i) # reproductibilité de l'expérience\n",
    "        \n",
    "        # read HR ground truth\n",
    "        hr_img=wgenpatex.imread(args.target_image_path)\n",
    "        hr_img=tv_resize(256, antialias=True)(hr_img)\n",
    "\n",
    "        lr_img=wgenpatex.imread(args.target_image_path)\n",
    "        lr_img=tv_resize(256, antialias=True)(lr_img)\n",
    "        args.size=lr_img.shape[2:4]\n",
    "        lr_img_=np.zeros((3,lr_img.shape[2]+2*add_boundary,lr_img.shape[3]+2*add_boundary))\n",
    "        if add_boundary>0:\n",
    "            lr_img_[:,add_boundary:-add_boundary,add_boundary:-add_boundary]=lr_img.squeeze().cpu().numpy()\n",
    "        else:\n",
    "            lr_img_=lr_img.squeeze().cpu().numpy()\n",
    "\n",
    "        # create (artificially) LR observation\n",
    "        lr_img=operator(torch.tensor(lr_img_,dtype=torch.float,device=DEVICE).view(1,3,lr_img_.shape[1],lr_img_.shape[2]))\n",
    "        lr_img+=0.01*torch.randn_like(lr_img)\n",
    "        \n",
    "\n",
    "\n",
    "        # build initialization by rescaling the lr observation and extending it to the boundary\n",
    "        upscaled=skimage.transform.resize(lr_img.squeeze().cpu().numpy(),[3,lr_img.shape[2]*stride,lr_img.shape[3]*stride])\n",
    "        diff=args.size[0]-upscaled.shape[1]\n",
    "\n",
    "        init=np.zeros((3,args.size[0],args.size[1]),dtype=bool)\n",
    "        init[:,diff//2:-diff//2,diff//2:-diff//2]=True\n",
    "        grid_x=np.array(range(init.shape[1]))\n",
    "        grid_x=np.tile(grid_x[:,np.newaxis],[1,init.shape[2]])\n",
    "        grid_y=np.array(range(init.shape[2]))\n",
    "        grid_y=np.tile(grid_y[np.newaxis,:],[init.shape[1],1])\n",
    "        points_x=np.reshape(grid_x[init[0,:,:]],[-1])\n",
    "        points_y=np.reshape(grid_y[init[0,:,:]],[-1])\n",
    "        init=init.astype(float)\n",
    "        for k in range(3):\n",
    "            values=np.reshape(upscaled[k,:,:],[-1])\n",
    "            points=np.stack([points_x,points_y],0).transpose()\n",
    "            init[k,:,:]=griddata(points,values,(grid_x,grid_y),method='nearest')\n",
    "            #print(init.shape)\n",
    "        init_=np.random.uniform(size=(3,init.shape[1]+2*add_boundary,init.shape[2]+2*add_boundary))\n",
    "        if add_boundary==0:\n",
    "            init_=init\n",
    "        else:\n",
    "            init_[:,add_boundary:-add_boundary,add_boundary:-add_boundary]=init\n",
    "        args.size=init_.shape\n",
    "\n",
    "        # load learn img\n",
    "        learn_img=wgenpatex.imread(args.learn_image_path)\n",
    "        learn_img=tv_resize(256, antialias=True)(learn_img)\n",
    "        print(learn_img.dtype)\n",
    "\n",
    "       # run reconstruction\n",
    "        synth_img= wgenpatex.optim_synthesis_SR(args,operator,lr_img,learn_img,args.lam,ρ=0.01,init=init_,add_boundary=add_boundary)\n",
    "\n",
    "        # save reconstruction\n",
    "        #if not os.path.isdir('output_imgs_diam'):\n",
    "            #os.mkdir('output_imgs_diam')\n",
    "\n",
    "        #wgenpatex.imsave('output_imgs_diam/synthesized_no_crop_bound.png', synth_img)\n",
    "        if add_boundary>0:\n",
    "            synth_img=synth_img[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary]\n",
    "        # Restored image \n",
    "        list_im_rest_WPPSU[j].append(synth_img)\n",
    "        # PSNR\n",
    "        list_psnr_WPPSU[j].append(PSNR(torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')),\n",
    "                                torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu'))))\n",
    "        # LPIPS\n",
    "        list_lpips_WPPSU[j].append(loss_fn_alex(torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')).unsqueeze(0)\n",
    "                                          , torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu')).unsqueeze(0)))\n",
    "        \n",
    "        # SSIM\n",
    "        img_hr=torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')).detach().numpy().transpose(1, 2, 0)\n",
    "        img_pred_WPPSU=torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu')).detach().numpy().transpose(1, 2, 0)\n",
    "        list_ssim_WPPSU[j].append(ssim(img_hr, img_pred_WPPSU,data_range=img_pred_WPPSU.max() - img_pred_WPPSU.min(),multichannel=True))\n",
    "        print(i)\n",
    "\n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/WPP/OT_SUOT')\n",
    "torch.save(list_psnr_WPPSU,\"list_psnr_WPPSU_color\")\n",
    "torch.save(list_lpips_WPPSU,\"list_lpips_WPPSU_color\")\n",
    "torch.save(list_ssim_WPPSU,\"list_ssim_WPPSU_color\")\n",
    "torch.save(list_im_rest_WPPSU,\"list_im_rest_WPPSU_color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af43c05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WPP_color",
   "language": "python",
   "name": "wpp_color"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
