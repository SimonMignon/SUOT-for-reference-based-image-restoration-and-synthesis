{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a4b5a0",
   "metadata": {},
   "source": [
    "# WPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebfd205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/WPP/OT_SUOT', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python37.zip', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/lib-dynload', '', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/IPython/extensions', '/home/prof/smignon/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "  \n",
    "# Prints the list of directories that the \n",
    "# interpreter will search for the required module. \n",
    "print(sys.path)\n",
    "\n",
    "sys.path.insert(0, \"/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015b8974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 - elapsed 0s - loss = 0.44148455901630224, wloss = 0.4005368944872171, oloss = 0.04094766452908516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 50 - elapsed 9s - loss = 0.04654542612284285, wloss = 0.043637916207312166, oloss = 0.0029075099155306816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100 - elapsed 20s - loss = 0.03125158735773326, wloss = 0.028111100813735135, oloss = 0.003140486543998122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 150 - elapsed 31s - loss = 0.030907877694779984, wloss = 0.027623163044417254, oloss = 0.00328471465036273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 200 - elapsed 43s - loss = 0.03210480267442506, wloss = 0.02882691904231649, oloss = 0.003277883632108569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 250 - elapsed 54s - loss = 0.033695402495496296, wloss = 0.030404930408977293, oloss = 0.003290472086519003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 300 - elapsed 66s - loss = 0.03513225962653621, wloss = 0.03183794769704207, oloss = 0.0032943119294941425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 350 - elapsed 78s - loss = 0.03659563499765284, wloss = 0.033288613774644205, oloss = 0.0033070212230086327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 400 - elapsed 90s - loss = 0.037704988060468736, wloss = 0.034357910886356535, oloss = 0.0033470771741122007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 450 - elapsed 103s - loss = 0.03873749871503662, wloss = 0.03535787926752221, oloss = 0.003379619447514415\n",
      "DONE - total time is 115s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 - elapsed 0s - loss = 0.48349132731202993, wloss = 0.44254366278294477, oloss = 0.04094766452908516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 50 - elapsed 9s - loss = 0.04594942640699351, wloss = 0.04332298848032856, oloss = 0.0026264379266649485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100 - elapsed 20s - loss = 0.02415741889215539, wloss = 0.02156030924468766, oloss = 0.0025971096474677324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 150 - elapsed 31s - loss = 0.02388948324880147, wloss = 0.021335330855087875, oloss = 0.0025541523937135935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 200 - elapsed 43s - loss = 0.024628483321876615, wloss = 0.022113825058923453, oloss = 0.002514658262953162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 250 - elapsed 54s - loss = 0.025605161593844628, wloss = 0.023124555045356487, oloss = 0.00248060654848814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 300 - elapsed 66s - loss = 0.026567173671594446, wloss = 0.024108244587353056, oloss = 0.0024589290842413902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 350 - elapsed 78s - loss = 0.027392507313507508, wloss = 0.024938914940449308, oloss = 0.0024535923730582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 400 - elapsed 90s - loss = 0.028234400252600267, wloss = 0.025773860678796723, oloss = 0.002460539573803544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 450 - elapsed 103s - loss = 0.028639746014761158, wloss = 0.026169171673046776, oloss = 0.002470574341714382\n",
      "DONE - total time is 115s\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# This code belongs to the paper\n",
    "#\n",
    "# J. Hertrich, A. Houdard and C. Redenbach.\n",
    "# Wasserstein Patch Prior for Image Superresolution.\n",
    "# IEEE Transactions on Computational Imaging, 2022.\n",
    "#\n",
    "# Please cite the paper, if you use this code.\n",
    "#\n",
    "# This script applies the Wasserstein Patch Prior reconstruction onto the 2D SiC Diamonds image\n",
    "# from Section 4.2 of the paper.\n",
    "#\n",
    "import argparse\n",
    "import wgenpatex as wgenpatex\n",
    "import torch\n",
    "import skimage.transform\n",
    "from skimage import (color, data, measure)\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import os\n",
    "import lpips\n",
    "import glob\n",
    "from torchvision.transforms import Resize as tv_resize\n",
    "import torchvision\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "torch.cuda.set_device(2)\n",
    "\n",
    "# images PATH\n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/Datasets/18_images_wa_woa_dataset')  \n",
    "\n",
    "list_im_name   = [file for file in glob.glob(\"HR/*.png\")]#.sort()\n",
    "list_im_modele_with_a   = [file for file in glob.glob(\"HR_with_anomalies/*.png\")]#.sort()\n",
    "list_im_modele_without_a   = [file for file in glob.glob(\"HR_without_anomalies/*.png\")]#.sort()\n",
    "\n",
    "list_im_name.sort()\n",
    "list_im_modele_with_a.sort()\n",
    "list_im_modele_without_a.sort()\n",
    "list_im_modele=[list_im_modele_with_a,list_im_modele_without_a]\n",
    "\n",
    "\n",
    "# lists\n",
    "#PSNR\n",
    "def PSNR(im,im_new):\n",
    "    M,N=im_new.shape\n",
    "    EQM=1/(M*N)*torch.sum((im-im_new)**2)\n",
    "    psnr=10*torch.log10(1/EQM)\n",
    "    return(psnr)\n",
    "\n",
    "list_psnr_WPP=[[],[]]\n",
    "\n",
    "# Restored iamges\n",
    "list_im_rest_WPP=[[],[]]\n",
    "\n",
    "# lr img\n",
    "list_im_LR=[[],[]]\n",
    "\n",
    "# LPIPS\n",
    "loss_fn_alex = lpips.LPIPS(net='alex')\n",
    "list_lpips_WPP=[[],[]]\n",
    "\n",
    "# SSIM\n",
    "list_ssim_WPP=[[],[]]\n",
    "\n",
    "# for i,name_im in enumerate(list_im_name): # RUN ALL IMAGES \n",
    "for i,name_im in enumerate([list_im_name[0]]): # TEST ON SINGLE IMAGE\n",
    "    for j in range(2):\n",
    "        # set arguments\n",
    "        args=argparse.Namespace()\n",
    "        args.target_image_path=name_im\n",
    "        args.scales=2\n",
    "        args.keops=True\n",
    "        args.n_iter_max=500\n",
    "        args.save=True\n",
    "        args.n_patches_out=10000\n",
    "        args.learn_image_path=list_im_modele[j][i]\n",
    "        args.patch_size=6\n",
    "        args.lam=(6000/args.patch_size**2)*(256**2/600**2)\n",
    "        args.n_iter_psi=10\n",
    "        args.n_patches_in=-1\n",
    "        args.visu=False\n",
    "\n",
    "\n",
    "        # define forward operator\n",
    "        blur_width=2.0\n",
    "        add_boundary=20\n",
    "        kernel_size=16\n",
    "        stride=4\n",
    "        my_layer=wgenpatex.gaussian_layer(kernel_size,blur_width,stride=stride)\n",
    "\n",
    "        def operator(inp):\n",
    "            if add_boundary==0:\n",
    "                return my_layer.forward(inp)\n",
    "            return my_layer.forward(inp[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary])\n",
    "        \n",
    "        torch.manual_seed(i) # reproductibility\n",
    "        \n",
    "        # read HR ground truth\n",
    "        hr_img=wgenpatex.imread(args.target_image_path)\n",
    "        hr_img=tv_resize(256, antialias=True)((0.2989 * hr_img[:,0,:, :] + 0.5870 * hr_img[:,1, :, :] + 0.1140 * hr_img[:,2, :, :]).unsqueeze(1))\n",
    "\n",
    "        lr_img=wgenpatex.imread(args.target_image_path)\n",
    "        lr_img=tv_resize(256, antialias=True)((0.2989 * lr_img[:,0,:, :] + 0.5870 * lr_img[:,1, :, :] + 0.1140 * lr_img[:,2, :, :]).unsqueeze(1))\n",
    "        args.size=lr_img.shape[2:4]\n",
    "        lr_img_=np.zeros((lr_img.shape[2]+2*add_boundary,lr_img.shape[3]+2*add_boundary))\n",
    "        if add_boundary>0:\n",
    "            lr_img_[add_boundary:-add_boundary,add_boundary:-add_boundary]=lr_img.squeeze().cpu().numpy()\n",
    "        else:\n",
    "            lr_img_=lr_img.squeeze().cpu().numpy()\n",
    "\n",
    "        # create (artificially) LR observation\n",
    "        lr_img=operator(torch.tensor(lr_img_,dtype=torch.float,device=DEVICE).view(1,1,lr_img_.shape[0],lr_img_.shape[1]))\n",
    "        lr_img+=0.01*torch.randn_like(lr_img)\n",
    "        #wgenpatex.imsave('input_imgs/lr_diam.png',lr_img)\n",
    "\n",
    "\n",
    "        # build initialization by rescaling the lr observation and extending it to the boundary\n",
    "        upscaled=skimage.transform.resize(lr_img.squeeze().cpu().numpy(),[lr_img.shape[2]*stride,lr_img.shape[3]*stride])\n",
    "        diff=args.size[0]-upscaled.shape[0]\n",
    "\n",
    "        init=np.zeros(args.size,dtype=bool)\n",
    "        init[diff//2:-diff//2,diff//2:-diff//2]=True\n",
    "        grid_x=np.array(range(init.shape[0]))\n",
    "        grid_x=np.tile(grid_x[:,np.newaxis],[1,init.shape[1]])\n",
    "        grid_y=np.array(range(init.shape[1]))\n",
    "        grid_y=np.tile(grid_y[np.newaxis,:],[init.shape[0],1])\n",
    "        points_x=np.reshape(grid_x[init],[-1])\n",
    "        points_y=np.reshape(grid_y[init],[-1])\n",
    "        values=np.reshape(upscaled,[-1])\n",
    "        points=np.stack([points_x,points_y],0).transpose()\n",
    "        init=griddata(points,values,(grid_x,grid_y),method='nearest')\n",
    "        init_=np.random.uniform(size=(init.shape[0]+2*add_boundary,init.shape[1]+2*add_boundary))\n",
    "        if add_boundary==0:\n",
    "            init_=init\n",
    "        else:\n",
    "            init_[add_boundary:-add_boundary,add_boundary:-add_boundary]=init\n",
    "        args.size=init_.shape\n",
    "\n",
    "        # load learn img\n",
    "        learn_img=wgenpatex.imread(args.learn_image_path)\n",
    "        learn_img=tv_resize(256, antialias=True)((0.2989 * learn_img[:,0,:, :] + 0.5870 * learn_img[:,1, :, :] + 0.1140 * learn_img[:,2, :, :]).unsqueeze(1))\n",
    "        print(learn_img.dtype)\n",
    "\n",
    "        # run reconstruction\n",
    "        synth_img= wgenpatex.optim_synthesis(args,operator,lr_img,learn_img,args.lam,init=init_,add_boundary=add_boundary)\n",
    "\n",
    "        if add_boundary>0:\n",
    "            synth_img=synth_img[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary]\n",
    "\n",
    "        list_im_rest_WPP[j].append(synth_img)\n",
    "        list_psnr_WPP[j].append(PSNR(torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')),\n",
    "                                torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu'))))\n",
    "\n",
    "        list_lpips_WPP[j].append(loss_fn_alex(torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)\n",
    "                                          , torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)))\n",
    "        \n",
    "        # SSIM\n",
    "        img_hr=torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')).detach().numpy()\n",
    "        img_pred_WPP=torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu')).detach().numpy()\n",
    "        list_ssim_WPP[j].append(ssim(img_hr, img_pred_WPP,data_range=img_pred_WPP.max() - img_pred_WPP.min()))\n",
    "        print(i)\n",
    "\n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/WPP/OT_SUOT') \n",
    "torch.save(list_psnr_WPP,\"list_psnr_WPP\")\n",
    "torch.save(list_lpips_WPP,\"list_lpips_WPP\")\n",
    "torch.save(list_ssim_WPP,\"list_ssim_WPP\")\n",
    "torch.save(list_im_rest_WPP,\"list_im_rest_WPP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63892bac",
   "metadata": {},
   "source": [
    "# WPPSU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70237dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/lpips/weights/v0.1/alex.pth\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 - elapsed 0s - loss = 0.34382583311526105, wloss = 0.3028781685861759, oloss = 0.04094766452908516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 50 - elapsed 9s - loss = 0.3154049883596599, wloss = 0.2895002025179565, oloss = 0.025904785841703415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100 - elapsed 17s - loss = 0.31282070570159703, wloss = 0.28705770254600793, oloss = 0.025763003155589104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 150 - elapsed 26s - loss = 0.31316940812394023, wloss = 0.28739070473238826, oloss = 0.02577870339155197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 200 - elapsed 35s - loss = 0.31577573635149747, wloss = 0.29001202166546136, oloss = 0.02576371468603611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 250 - elapsed 44s - loss = 0.3123007846297696, wloss = 0.28661222953815013, oloss = 0.02568855509161949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 300 - elapsed 53s - loss = 0.3148857973283157, wloss = 0.2891425866400823, oloss = 0.025743210688233376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 350 - elapsed 62s - loss = 0.31289385887794197, wloss = 0.2871284845750779, oloss = 0.025765374302864075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 400 - elapsed 70s - loss = 0.31422740733250976, wloss = 0.2885154443792999, oloss = 0.025711962953209877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 450 - elapsed 79s - loss = 0.31279169500339776, wloss = 0.2870479404227808, oloss = 0.02574375458061695\n",
      "DONE - total time is 88s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 - elapsed 0s - loss = 0.3510368379938882, wloss = 0.310089173464803, oloss = 0.04094766452908516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 50 - elapsed 8s - loss = 0.31653955433284864, wloss = 0.2914858855656348, oloss = 0.02505366876721382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100 - elapsed 17s - loss = 0.31465076887980103, wloss = 0.28950416715815663, oloss = 0.0251466017216444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 150 - elapsed 26s - loss = 0.3163250861107372, wloss = 0.2911794920801185, oloss = 0.025145594030618668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 200 - elapsed 35s - loss = 0.313397447578609, wloss = 0.28824157547205687, oloss = 0.025155872106552124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 250 - elapsed 44s - loss = 0.3143176601151936, wloss = 0.28916387230856344, oloss = 0.025153787806630135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 300 - elapsed 52s - loss = 0.31415976368589327, wloss = 0.28902642213506624, oloss = 0.025133341550827026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 350 - elapsed 61s - loss = 0.3170935559319332, wloss = 0.2919520299183205, oloss = 0.025141526013612747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 400 - elapsed 70s - loss = 0.31541887333150953, wloss = 0.29028618743177503, oloss = 0.025132685899734497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 450 - elapsed 79s - loss = 0.31778490875149146, wloss = 0.2926421031006612, oloss = 0.02514280565083027\n",
      "DONE - total time is 87s\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Adaptated from\n",
    "#\n",
    "# J. Hertrich, A. Houdard and C. Redenbach.\n",
    "# Wasserstein Patch Prior for Image Superresolution.\n",
    "# IEEE Transactions on Computational Imaging, 2022.\n",
    "#\n",
    "#\n",
    "\n",
    "import argparse\n",
    "import wgenpatex_SU as wgenpatex\n",
    "import torch\n",
    "import skimage.transform\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import os\n",
    "import lpips\n",
    "import glob\n",
    "from torchvision.transforms import Resize as tv_resize\n",
    "from skimage import (color, data, measure)\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import torchvision \n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "torch.cuda.set_device(2)\n",
    "\n",
    "# images PATH\n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/Datasets/18_images_wa_woa_dataset')  \n",
    "\n",
    "list_im_name   = [file for file in glob.glob(\"HR/*.png\")]#.sort()\n",
    "list_im_modele_with_a   = [file for file in glob.glob(\"HR_with_anomalies/*.png\")]#.sort()\n",
    "list_im_modele_without_a   = [file for file in glob.glob(\"HR_without_anomalies/*.png\")]#.sort()\n",
    "\n",
    "list_im_name.sort()\n",
    "list_im_modele_with_a.sort()\n",
    "list_im_modele_without_a.sort()\n",
    "list_im_modele=[list_im_modele_with_a,list_im_modele_without_a]\n",
    "\n",
    "# lists\n",
    "#PSNR\n",
    "def PSNR(im,im_new):\n",
    "    M,N=im_new.shape\n",
    "    EQM=1/(M*N)*torch.sum((im-im_new)**2)\n",
    "    psnr=10*torch.log10(1/EQM)\n",
    "    return(psnr)\n",
    "\n",
    "list_psnr_WPPSU=[[],[]]\n",
    "\n",
    "# im_rest\n",
    "list_im_rest_WPPSU=[[],[]]\n",
    "\n",
    "# LR_img\n",
    "list_im_LR=[[],[]]\n",
    "\n",
    "# LPIPS\n",
    "loss_fn_alex = lpips.LPIPS(net='alex') # best forward scores\n",
    "list_lpips_WPPSU=[[],[]]\n",
    "\n",
    "# SSIM\n",
    "list_ssim_WPPSU=[[],[]]\n",
    "\n",
    "# for i,name_im in enumerate(list_im_name): # RUN ALL IMAGES \n",
    "for i,name_im in enumerate([list_im_name[0]]): # TEST ON SINGLE IMAGE\n",
    "    for j in range(2):\n",
    "        # set arguments\n",
    "        args=argparse.Namespace()\n",
    "        args.target_image_path=name_im\n",
    "        args.scales=2\n",
    "        args.keops=True\n",
    "        args.n_iter_max=500\n",
    "        args.save=True\n",
    "        args.n_patches_out=10\n",
    "        args.learn_image_path=list_im_modele[j][i]\n",
    "        args.patch_size=6\n",
    "        args.lam=(6000/args.patch_size**2)*(256**2/600**2)\n",
    "        args.n_iter_psi=10\n",
    "        args.n_patches_in=-1\n",
    "        args.visu=False\n",
    "\n",
    "\n",
    "        # define forward operator\n",
    "        blur_width=2.0\n",
    "        add_boundary=0\n",
    "        kernel_size=16\n",
    "        stride=4\n",
    "        my_layer=wgenpatex.gaussian_layer(kernel_size,blur_width,stride=stride)\n",
    "\n",
    "        def operator(inp):\n",
    "            if add_boundary==0:\n",
    "                return my_layer.forward(inp)\n",
    "            return my_layer.forward(inp[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary])\n",
    "        \n",
    "        torch.manual_seed(i) # reproductibility\n",
    "        \n",
    "        # read HR ground truth\n",
    "        hr_img=wgenpatex.imread(args.target_image_path)\n",
    "        hr_img=tv_resize(256, antialias=True)((0.2989 * hr_img[:,0,:, :] + 0.5870 * hr_img[:,1, :, :] + 0.1140 * hr_img[:,2, :, :]).unsqueeze(1))\n",
    "\n",
    "        lr_img=wgenpatex.imread(args.target_image_path)\n",
    "        lr_img=tv_resize(256, antialias=True)((0.2989 * lr_img[:,0,:, :] + 0.5870 * lr_img[:,1, :, :] + 0.1140 * lr_img[:,2, :, :]).unsqueeze(1))\n",
    "        args.size=lr_img.shape[2:4]\n",
    "        lr_img_=np.zeros((lr_img.shape[2]+2*add_boundary,lr_img.shape[3]+2*add_boundary))\n",
    "        if add_boundary>0:\n",
    "            lr_img_[add_boundary:-add_boundary,add_boundary:-add_boundary]=lr_img.squeeze().cpu().numpy()\n",
    "        else:\n",
    "            lr_img_=lr_img.squeeze().cpu().numpy()\n",
    "\n",
    "        # create (artificially) LR observation\n",
    "        lr_img=operator(torch.tensor(lr_img_,dtype=torch.float,device=DEVICE).view(1,1,lr_img_.shape[0],lr_img_.shape[1]))\n",
    "        lr_img+=0.01*torch.randn_like(lr_img)\n",
    "        #wgenpatex.imsave('input_imgs/lr_diam.png',lr_img)\n",
    "\n",
    "\n",
    "        # build initialization by rescaling the lr observation and extending it to the boundary\n",
    "        upscaled=skimage.transform.resize(lr_img.squeeze().cpu().numpy(),[lr_img.shape[2]*stride,lr_img.shape[3]*stride])\n",
    "        diff=args.size[0]-upscaled.shape[0]\n",
    "\n",
    "        init=np.zeros(args.size,dtype=bool)\n",
    "        init[diff//2:-diff//2,diff//2:-diff//2]=True\n",
    "        grid_x=np.array(range(init.shape[0]))\n",
    "        grid_x=np.tile(grid_x[:,np.newaxis],[1,init.shape[1]])\n",
    "        grid_y=np.array(range(init.shape[1]))\n",
    "        grid_y=np.tile(grid_y[np.newaxis,:],[init.shape[0],1])\n",
    "        points_x=np.reshape(grid_x[init],[-1])\n",
    "        points_y=np.reshape(grid_y[init],[-1])\n",
    "        values=np.reshape(upscaled,[-1])\n",
    "        points=np.stack([points_x,points_y],0).transpose()\n",
    "        init=griddata(points,values,(grid_x,grid_y),method='nearest')\n",
    "        init_=np.random.uniform(size=(init.shape[0]+2*add_boundary,init.shape[1]+2*add_boundary))\n",
    "        if add_boundary==0:\n",
    "            init_=init\n",
    "        else:\n",
    "            init_[add_boundary:-add_boundary,add_boundary:-add_boundary]=init\n",
    "        args.size=init_.shape\n",
    "\n",
    "        # load learn img\n",
    "        learn_img=wgenpatex.imread(args.learn_image_path)\n",
    "        learn_img=tv_resize(256, antialias=True)((0.2989 * learn_img[:,0,:, :] + 0.5870 * learn_img[:,1, :, :] + 0.1140 * learn_img[:,2, :, :]).unsqueeze(1))\n",
    "        print(learn_img.dtype)\n",
    "\n",
    "        # run reconstruction\n",
    "        synth_img= wgenpatex.optim_synthesis(args,operator,lr_img,learn_img,args.lam,Ï=0.01,init=init_,add_boundary=add_boundary)\n",
    "\n",
    "\n",
    "        if add_boundary>0:\n",
    "            synth_img=synth_img[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary]\n",
    "        \n",
    "        list_im_rest_WPPSU[j].append(synth_img)\n",
    "        list_psnr_WPPSU[j].append(PSNR(torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')),\n",
    "                                torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu'))))\n",
    "        # LPIPS\n",
    "        list_lpips_WPPSU[j].append(loss_fn_alex(torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)\n",
    "                                          , torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)))\n",
    "        \n",
    "        # SSIM\n",
    "        img_hr=torchvision.transforms.CenterCrop(256-12)(hr_img.squeeze().to('cpu')).detach().numpy()\n",
    "        img_pred_WPPSU=torchvision.transforms.CenterCrop(256-12)(synth_img.squeeze().to('cpu')).detach().numpy()\n",
    "        list_ssim_WPPSU[j].append(ssim(img_hr, img_pred_WPPSU,data_range=img_pred_WPPSU.max() - img_pred_WPPSU.min()))\n",
    "        \n",
    "        print(i)\n",
    "\n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/WPP/OT_SUOT') \n",
    "torch.save(list_psnr_WPPSU,\"list_psnr_WPPSU\")\n",
    "torch.save(list_lpips_WPPSU,\"list_lpips_WPPSU\")\n",
    "torch.save(list_im_rest_WPPSU,\"list_im_rest_WPPSU\")\n",
    "torch.save(list_ssim_WPPSU,\"list_ssim_WPPSU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e3efb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WPP_color",
   "language": "python",
   "name": "wpp_color"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
