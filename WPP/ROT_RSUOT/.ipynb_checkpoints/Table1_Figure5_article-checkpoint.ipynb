{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661eae97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pykeops.torch import LazyTensor\n",
    "import numpy as np\n",
    "from torchvision.transforms import Resize as tv_resize\n",
    "from PIL import Image\n",
    "import time\n",
    "from torch import nn\n",
    "import math\n",
    "import skimage.io as io\n",
    "import os\n",
    "import skimage.transform\n",
    "import skimage.metrics as sm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.interpolate import griddata\n",
    "import lpips\n",
    "import torchvision\n",
    "import glob\n",
    "import argparse\n",
    "import wgenpatex as wgenpatex\n",
    "from ROT_RSUOT_RUOT import ROT,RSUOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e712bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/WPP/ROT_RSUOT', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python37.zip', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/lib-dynload', '', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/IPython/extensions', '/home/prof/smignon/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "  \n",
    "# Prints the list of directories that the \n",
    "# interpreter will search for the required module. \n",
    "print(sys.path)\n",
    "\n",
    "sys.path.insert(0, \"/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a1635",
   "metadata": {},
   "source": [
    "### Functions for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a568922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "def PSNR(im,im_new): \n",
    "    '''\n",
    "    Compute PSNR\n",
    "    '''\n",
    "    M,N=im_new.shape\n",
    "    EQM=1/(M*N)*torch.sum((im-im_new)**2)\n",
    "    psnr=10*torch.log10(1/EQM)\n",
    "    return(psnr)\n",
    "\n",
    "def show(im_deb,col=False):\n",
    "    '''\n",
    "    show image \n",
    "    '''\n",
    "    im_deb=im_deb.clone().detach()\n",
    "    im_deb[im_deb>1]=1\n",
    "    im_deb[im_deb<0]=0\n",
    "    if col==True:\n",
    "        im_deb=(255*im_deb.permute(1, 2, 0)).type(dtype=torch.uint8)\n",
    "    else:\n",
    "        im_deb=(255*im_deb).type(dtype=torch.uint8)\n",
    "    imgpil = Image.fromarray(im_deb.numpy()) \n",
    "    display(imgpil)\n",
    "    \n",
    "loss_fn_alex = lpips.LPIPS(net='alex') # compute LPIPS\n",
    "\n",
    "    \n",
    "def sinkhorn_super_resolution(operator, high_resolution_image,low_resolution_image,init,\n",
    "                              loss_fct,lbd, niters, patch_size,\n",
    "                              n_patches_out, device, verbose,lr):\n",
    "    \n",
    "    # parameters for Gaussian downsampling\n",
    "    gaussian_kernel_size = 4\n",
    "    gaussian_std = 1\n",
    "    stride = 2\n",
    "    n_scales=2\n",
    "    \n",
    "    # Downsampling operators for the high resolution reference image (target_downsampler) and x (x_downsampler)\n",
    "    target_downsampler = wgenpatex.create_gaussian_pyramid(gaussian_kernel_size, gaussian_std, n_scales+1, stride, pad=False,dim=2)                  \n",
    "    x_downsampler = wgenpatex.create_gaussian_pyramid(gaussian_kernel_size, gaussian_std, n_scales+1, stride, pad=False,dim=2)\n",
    "\n",
    "    # Initialization of x\n",
    "    x = torch.tensor(init[np.newaxis,np.newaxis,:,:],dtype=torch.float,device=device).requires_grad_() \n",
    "    y = low_resolution_image\n",
    "    \n",
    "    # Gaussian downsampling of the high resolution reference image\n",
    "    target_downsampler(high_resolution_image)\n",
    "    \n",
    "    # Downsampling operators for the high resolution reference image (target_im2pat) and x (input_im2pat)\n",
    "    target_im2pat = wgenpatex.patch_extractor(patch_size, pad=False,center=False,dim=2)\n",
    "    input_im2pat = wgenpatex.patch_extractor(patch_size, pad=False,center=False,dim=2)\n",
    "    \n",
    "    # Exctract patches from the high resolution reference image\n",
    "    nuM = target_im2pat(target_downsampler[0].down_img, n_patches_out).contiguous()\n",
    "    nuM_ds = target_im2pat(target_downsampler[1].down_img, n_patches_out).contiguous()\n",
    "    \n",
    "    # Set the optimizer\n",
    "    optimizer = torch.optim.Adam([x], lr=lr)\n",
    "    \n",
    "    # Initialise dual variables\n",
    "    fg_i=None\n",
    "    fg_i_ds=None\n",
    "    \n",
    "    # Initialise computation time\n",
    "    torch.cuda.synchronize()\n",
    "    t = time.time()\n",
    "    \n",
    "    # Gradient descent \n",
    "    for i in range(niters):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        # Create gaussian pyramid from x\n",
    "        x_downsampler(x)\n",
    "        \n",
    "        # Evaluate OT cost at each scale \n",
    "        # scale L=0:\n",
    "        nuX = input_im2pat(x_downsampler[0].down_img, -1,split=[1,0]).contiguous()\n",
    "        l1,fg_i=loss_fct(nuX, nuM,fg_i) #OTSD\n",
    "\n",
    "        # scale L=1:\n",
    "        nuX_ds = input_im2pat(x_downsampler[1].down_img, -1,split=[1,0]).contiguous()\n",
    "        l1_ds,fg_i_ds=loss_fct(nuX_ds,nuM_ds,fg_i_ds) #OTSD\n",
    "\n",
    "        # Evaluate data attachment term\n",
    "        l2 = torch.sum((operator(x)-y)**2)\n",
    "        \n",
    "        # Evaluate cost function\n",
    "        l = 1/2*l1+1/2*l1_ds + 1/2*lbd*l2\n",
    "        \n",
    "        # Compute the gradient\n",
    "        l.backward()\n",
    "        \n",
    "        if verbose==True:\n",
    "            print('OT:', \"{:.10f}\".format(0.5*(l1+l1_ds)),'attache:', \"{:.10f}\".format(0.5*lbd*l2),'l:', \"{:.10f}\".format(l))\n",
    "            print('i=',i)\n",
    "            print('-------------------------------------------------------------------')\n",
    "        \n",
    "        \n",
    "        # Update x\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Computation time \n",
    "    torch.cuda.synchronize()\n",
    "    print('DONE - total time is '+str(int(time.time()-t))+'s')\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3163a4ac",
   "metadata": {},
   "source": [
    "### Results of Table 1 and Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4cad31e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE - total time is 229s\n",
      "DONE - total time is 229s\n",
      "Etape : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE - total time is 229s\n",
      "DONE - total time is 229s\n",
      "Etape : 0\n"
     ]
    }
   ],
   "source": [
    "# device \n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(2)\n",
    "\n",
    "# images PATH\n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/Datasets/18_images_wa_woa_dataset')  \n",
    "\n",
    "list_im_name   = [file for file in glob.glob(\"HR/*.png\")]#.sort()\n",
    "list_im_modele_with_a   = [file for file in glob.glob(\"HR_with_anomalies/*.png\")]#.sort()\n",
    "list_im_modele_without_a   = [file for file in glob.glob(\"HR_without_anomalies/*.png\")]#.sort()\n",
    "\n",
    "list_im_name.sort()\n",
    "list_im_modele_with_a.sort()\n",
    "list_im_modele_without_a.sort()\n",
    "list_im_modele=[list_im_modele_with_a,list_im_modele_without_a]\n",
    "\n",
    "# Initialise lists\n",
    "#PSNR [with defects, without defects]\n",
    "list_psnr_ROT=[[],[]]\n",
    "list_psnr_RSUOT=[[],[]]\n",
    "\n",
    "# im_rest\n",
    "list_im_restored_ROT=[[],[]]\n",
    "list_im_restored_RSUOT=[[],[]]\n",
    "\n",
    "# loss\n",
    "list_Loss_ROT=[[],[]]\n",
    "list_Loss_RSUOT=[[],[]]\n",
    "\n",
    "# lr img\n",
    "list_im_LR=[[],[]]\n",
    "\n",
    "#  img\n",
    "list_im_HR=[[],[]]\n",
    "\n",
    "# LPIPS\n",
    "list_lpips_ROT=[[],[]]\n",
    "list_lpips_RSUOT=[[],[]]\n",
    "\n",
    "# LPIPS\n",
    "list_ssim_ROT=[[],[]]\n",
    "list_ssim_RSUOT=[[],[]]\n",
    "\n",
    "# Super Resolution\n",
    "\n",
    "# Data attachment \n",
    "lamb=(36/6000)*(600**2/256**2)\n",
    "\n",
    "# for i,name_im in enumerate(list_im_name): # RUN ALL IMAGES \n",
    "for i,name_im in enumerate([list_im_name[0]]): # TEST ON SINGLE IMAGE\n",
    "    for j in range(2):\n",
    "        # set arguments\n",
    "        args=argparse.Namespace()\n",
    "        args.target_image_path=name_im\n",
    "        args.learn_image_path=list_im_modele[j][i]\n",
    "        args.patch_size=6\n",
    "        args.n_patches_out=10000\n",
    "        args.n_patches_in=-1\n",
    "\n",
    "\n",
    "        # Define forward operator\n",
    "        blur_width=2.0\n",
    "        add_boundary=0 # no artificial boundary \n",
    "        kernel_size=16\n",
    "        stride=4\n",
    "        my_layer=wgenpatex.gaussian_layer(kernel_size,blur_width,stride=stride)\n",
    "\n",
    "        def operator(inp):\n",
    "            if add_boundary==0:\n",
    "                return my_layer.forward(inp)\n",
    "            return my_layer.forward(inp[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary])\n",
    "        \n",
    "        # Reproductibility\n",
    "        torch.manual_seed(i)\n",
    "        \n",
    "        # Read HR ground truth\n",
    "        hr_img=wgenpatex.imread(args.target_image_path)\n",
    "        hr_img=tv_resize(256, antialias=True)((0.2989 * hr_img[:,0,:, :] + 0.5870 * hr_img[:,1, :, :] + 0.1140 * hr_img[:,2, :, :]).unsqueeze(1))\n",
    "        \n",
    "        # create (artificially) LR observation\n",
    "        lr_img=wgenpatex.imread(args.target_image_path)\n",
    "        lr_img=tv_resize(256, antialias=True)((0.2989 * lr_img[:,0,:, :] + 0.5870 * lr_img[:,1, :, :] + 0.1140 * lr_img[:,2, :, :]).unsqueeze(1))\n",
    "        args.size=lr_img.shape[2:4]\n",
    "        lr_img_=np.zeros((lr_img.shape[2]+2*add_boundary,lr_img.shape[3]+2*add_boundary))\n",
    "        \n",
    "        if add_boundary>0:\n",
    "            lr_img_[add_boundary:-add_boundary,add_boundary:-add_boundary]=lr_img.squeeze().cpu().numpy()\n",
    "        else:\n",
    "            lr_img_=lr_img.squeeze().cpu().numpy()\n",
    "\n",
    "        lr_img=operator(torch.tensor(lr_img_,dtype=torch.float,device=DEVICE).view(1,1,lr_img_.shape[0],lr_img_.shape[1]))\n",
    "        lr_img+=0.01*torch.randn_like(lr_img)\n",
    "\n",
    "\n",
    "        # build initialization by rescaling the lr observation and extending it to the boundary\n",
    "        upscaled=skimage.transform.resize(lr_img.squeeze().cpu().numpy(),[lr_img.shape[2]*stride,lr_img.shape[3]*stride])\n",
    "        diff=args.size[0]-upscaled.shape[0]\n",
    "\n",
    "        init=np.zeros(args.size,dtype=bool)\n",
    "        init[diff//2:-diff//2,diff//2:-diff//2]=True\n",
    "        grid_x=np.array(range(init.shape[0]))\n",
    "        grid_x=np.tile(grid_x[:,np.newaxis],[1,init.shape[1]])\n",
    "        grid_y=np.array(range(init.shape[1]))\n",
    "        grid_y=np.tile(grid_y[np.newaxis,:],[init.shape[0],1])\n",
    "        points_x=np.reshape(grid_x[init],[-1])\n",
    "        points_y=np.reshape(grid_y[init],[-1])\n",
    "        values=np.reshape(upscaled,[-1])\n",
    "        points=np.stack([points_x,points_y],0).transpose()\n",
    "        init=griddata(points,values,(grid_x,grid_y),method='nearest')\n",
    "        init_=np.random.uniform(size=(init.shape[0]+2*add_boundary,init.shape[1]+2*add_boundary))\n",
    "        if add_boundary==0:\n",
    "            init_=init\n",
    "        else:\n",
    "            init_[add_boundary:-add_boundary,add_boundary:-add_boundary]=init\n",
    "        args.size=init_.shape\n",
    "        \n",
    "        # Read HR reference image \n",
    "        learn_img=wgenpatex.imread(args.learn_image_path)\n",
    "        learn_img=tv_resize(256, antialias=True)((0.2989 * learn_img[:,0,:, :] + 0.5870 * learn_img[:,1, :, :] + 0.1140 * learn_img[:,2, :, :]).unsqueeze(1))\n",
    "        \n",
    "        # Define ROT\n",
    "        def R_OT(x,y,fg_init):\n",
    "            return(ROT(x,y,ε=1e-4,fg_init=fg_init,nb_it=10,dev=DEVICE))\n",
    "    \n",
    "        # Define RSUOT\n",
    "        def RSU_OT(x,y,f_init):\n",
    "            return(RSUOT(x,y,ε=1e-4,ρ=0.01,f_init=f_init,nb_it=10,dev=DEVICE))\n",
    "\n",
    "        # Super resolution with ROT\n",
    "        im_deb_ROT=sinkhorn_super_resolution(operator=operator, high_resolution_image=learn_img,\n",
    "                                                  low_resolution_image=lr_img,init=init_,\n",
    "                                                  loss_fct=R_OT,lbd=lamb, \n",
    "                                                  niters=500, patch_size=6,\n",
    "                                                  n_patches_out=10000,device=DEVICE,verbose=False,lr=0.01)\n",
    "        # Super resolution with RSUOT\n",
    "        im_deb_RSUOT=sinkhorn_super_resolution(operator=operator, high_resolution_image=learn_img,\n",
    "                                                  low_resolution_image=lr_img,init=init_,\n",
    "                                                  loss_fct=RSU_OT,lbd=lamb, \n",
    "                                                  niters=500, patch_size=6,\n",
    "                                                  n_patches_out=10000,device=DEVICE,verbose=False,lr=0.001)\n",
    "\n",
    "        print(\"Etape :\",i)\n",
    "\n",
    "        # Add measures to each list \n",
    "        # PSNR\n",
    "        list_psnr_ROT[j].append(PSNR(torchvision.transforms.CenterCrop(args.size[0]-12)(hr_img.squeeze().to('cpu')),\n",
    "                                torchvision.transforms.CenterCrop(args.size[0]-12)(im_deb_ROT.squeeze().to('cpu'))).item())\n",
    "        list_psnr_RSUOT[j].append(PSNR(torchvision.transforms.CenterCrop(args.size[0]-12)(hr_img.squeeze().to('cpu')),\n",
    "                                torchvision.transforms.CenterCrop(args.size[0]-12)(im_deb_RSUOT.squeeze().to(\"cpu\"))).item())\n",
    "        \n",
    "        # LPIPS\n",
    "        list_lpips_ROT[j].append(loss_fn_alex(torchvision.transforms.CenterCrop(args.size[0]-12)(hr_img.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)\n",
    "                                          , torchvision.transforms.CenterCrop(args.size[0]-12)(im_deb_ROT.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)))\n",
    "        list_lpips_RSUOT[j].append(loss_fn_alex(torchvision.transforms.CenterCrop(args.size[0]-12)(hr_img.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)\n",
    "                                          , torchvision.transforms.CenterCrop(args.size[0]-12)(im_deb_RSUOT.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)))\n",
    "        \n",
    "        # SSIM\n",
    "        img_hr=torchvision.transforms.CenterCrop(args.size[0]-12)(hr_img.squeeze().to('cpu')).detach().numpy()\n",
    "        img_pred_ROT=torchvision.transforms.CenterCrop(args.size[0]-12)(im_deb_ROT.squeeze().to('cpu')).detach().numpy()\n",
    "        img_pred_RSUOT=torchvision.transforms.CenterCrop(args.size[0]-12)(im_deb_RSUOT.squeeze().to('cpu')).detach().numpy()\n",
    "        \n",
    "        list_ssim_ROT[j].append(ssim(img_hr, img_pred_ROT,data_range=img_pred_ROT.max() - img_pred_ROT.min()))\n",
    "        list_ssim_RSUOT[j].append(ssim(img_hr, img_pred_RSUOT,data_range=img_pred_RSUOT.max() - img_pred_RSUOT.min()))\n",
    "        \n",
    "        # Resulting images \n",
    "        list_im_restored_ROT[j].append(im_deb_ROT.clone().to('cpu'))\n",
    "        list_im_restored_RSUOT[j].append(im_deb_RSUOT.clone().to('cpu'))\n",
    "        \n",
    "        # LR images \n",
    "        list_im_LR[j].append(lr_img.clone().to('cpu'))\n",
    "        \n",
    "        # HR images \n",
    "        list_im_HR[j].append(hr_img.clone().to('cpu'))\n",
    "\n",
    "# Save results \n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/WPP/ROT_RSUOT/')\n",
    "\n",
    "# PSNR\n",
    "torch.save(list_psnr_ROT,\"list_psnr_ROT\")\n",
    "torch.save(list_psnr_RSUOT,\"list_psnr_RSUOT\")\n",
    "\n",
    "# LPIPS\n",
    "torch.save(list_lpips_ROT,\"list_lpips_ROT\")\n",
    "torch.save(list_lpips_RSUOT,\"list_lpips_RSUOT\")\n",
    "\n",
    "# SSIM\n",
    "torch.save(list_ssim_ROT,\"list_ssim_ROT\")\n",
    "torch.save(list_ssim_RSUOT,\"list_ssim_RSUOT\")\n",
    "\n",
    "# RESTORED IMAGES\n",
    "torch.save(list_im_restored_ROT,\"list_im_restored_ROT\")\n",
    "torch.save(list_im_restored_RSUOT,\"list_im_restored_RSUOT\")\n",
    "\n",
    "# LR IMAGES\n",
    "torch.save(list_im_LR,\"list_im_LR\")\n",
    "\n",
    "# LR IMAGES\n",
    "torch.save(list_im_HR,\"list_im_HR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WPP_color",
   "language": "python",
   "name": "wpp_color"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
