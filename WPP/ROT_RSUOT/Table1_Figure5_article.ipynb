{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661eae97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pykeops.torch import LazyTensor\n",
    "import numpy as np\n",
    "from torchvision.transforms import Resize as tv_resize\n",
    "from PIL import Image\n",
    "import time\n",
    "from torch import nn\n",
    "import math\n",
    "import skimage.io as io\n",
    "import os\n",
    "import skimage.metrics as sm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import lpips\n",
    "import torchvision\n",
    "import glob\n",
    "import argparse\n",
    "import wgenpatex as wgenpatex\n",
    "from ROT_RSUOT_RUOT import ROT,RSUOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e712bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM', '/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/WPP/ROT_RSUOT', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python37.zip', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/lib-dynload', '', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages', '/home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/IPython/extensions', '/home/prof/smignon/.ipython', '/home/prof/smignon/.cache/keops2.1.2/Linux_gpu2.mapmo.univ-orleans.fr_6.6.4-arch1-1_p3.7.13']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "  \n",
    "# Prints the list of directories that the \n",
    "# interpreter will search for the required module. \n",
    "print(sys.path)\n",
    "\n",
    "sys.path.insert(0, \"/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a1635",
   "metadata": {},
   "source": [
    "### Functions for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a568922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/prof/smignon/anaconda3/envs/WPP_color/lib/python3.7/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "def PSNR(im,im_new): \n",
    "    '''\n",
    "    Compute PSNR\n",
    "    '''\n",
    "    M,N=im_new.shape\n",
    "    EQM=1/(M*N)*torch.sum((im-im_new)**2)\n",
    "    psnr=10*torch.log10(1/EQM)\n",
    "    return(psnr)\n",
    "\n",
    "def show(im_deb,col=False):\n",
    "    '''\n",
    "    show image \n",
    "    '''\n",
    "    im_deb=im_deb.clone().detach()\n",
    "    im_deb[im_deb>1]=1\n",
    "    im_deb[im_deb<0]=0\n",
    "    if col==True:\n",
    "        im_deb=(255*im_deb.permute(1, 2, 0)).type(dtype=torch.uint8)\n",
    "    else:\n",
    "        im_deb=(255*im_deb).type(dtype=torch.uint8)\n",
    "    imgpil = Image.fromarray(im_deb.numpy()) \n",
    "    display(imgpil)\n",
    "    \n",
    "loss_fn_alex = lpips.LPIPS(net='alex') # compute LPIPS\n",
    "\n",
    "    \n",
    "def sinkhorn_super_resolution(operator, high_resolution_image,low_resolution_image,init,\n",
    "                              loss_fct,lbd, niters, patch_size,\n",
    "                              n_patches_out, device, verbose,lr):\n",
    "    \n",
    "    # parameters for Gaussian downsampling\n",
    "    gaussian_kernel_size = 4\n",
    "    gaussian_std = 1\n",
    "    stride = 2\n",
    "    n_scales=2\n",
    "    \n",
    "    # Downsampling operators for the high resolution reference image (target_downsampler) and x (x_downsampler)\n",
    "    target_downsampler = wgenpatex.create_gaussian_pyramid(gaussian_kernel_size, gaussian_std, n_scales+1, stride, pad=False,dim=2)                  \n",
    "    x_downsampler = wgenpatex.create_gaussian_pyramid(gaussian_kernel_size, gaussian_std, n_scales+1, stride, pad=False,dim=2)\n",
    "\n",
    "    # Initialization of x\n",
    "    x = torch.tensor(init[np.newaxis,np.newaxis,:,:],dtype=torch.float,device=device).requires_grad_() \n",
    "    y = low_resolution_image\n",
    "    \n",
    "    # Gaussian downsampling of the high resolution reference image\n",
    "    target_downsampler(high_resolution_image)\n",
    "    \n",
    "    # Downsampling operators for the high resolution reference image (target_im2pat) and x (input_im2pat)\n",
    "    target_im2pat = wgenpatex.patch_extractor(patch_size, pad=False,center=False,dim=2)\n",
    "    input_im2pat = wgenpatex.patch_extractor(patch_size, pad=False,center=False,dim=2)\n",
    "    \n",
    "    # Exctract patches from the high resolution reference image\n",
    "    nuM = target_im2pat(target_downsampler[0].down_img, n_patches_out).contiguous()\n",
    "    nuM_ds = target_im2pat(target_downsampler[1].down_img, n_patches_out).contiguous()\n",
    "    \n",
    "    # Set the optimizer\n",
    "    optimizer = torch.optim.Adam([x], lr=lr)\n",
    "    \n",
    "    # Initialise dual variables\n",
    "    fg_i=None\n",
    "    fg_i_ds=None\n",
    "    \n",
    "    # Initialise computation time\n",
    "    torch.cuda.synchronize()\n",
    "    t = time.time()\n",
    "    \n",
    "    # Gradient descent \n",
    "    for i in range(niters):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        # Create gaussian pyramid from x\n",
    "        x_downsampler(x)\n",
    "        \n",
    "        # Evaluate OT cost at each scale \n",
    "        # scale L=0:\n",
    "        nuX = input_im2pat(x_downsampler[0].down_img, -1,split=[1,0]).contiguous()\n",
    "        l1,fg_i=loss_fct(nuX, nuM,fg_i) #OTSD\n",
    "\n",
    "        # scale L=1:\n",
    "        nuX_ds = input_im2pat(x_downsampler[1].down_img, -1,split=[1,0]).contiguous()\n",
    "        l1_ds,fg_i_ds=loss_fct(nuX_ds,nuM_ds,fg_i_ds) #OTSD\n",
    "\n",
    "        # Evaluate data attachment term\n",
    "        l2 = torch.sum((operator(x)-y)**2)\n",
    "        \n",
    "        # Evaluate cost function\n",
    "        l = 1/2*l1+1/2*l1_ds + 1/2*lbd*l2\n",
    "        \n",
    "        # Compute the gradient\n",
    "        l.backward()\n",
    "        \n",
    "        if verbose==True:\n",
    "            print('OT:', \"{:.10f}\".format(0.5*(l1+l1_ds)),'attache:', \"{:.10f}\".format(0.5*lbd*l2),'l:', \"{:.10f}\".format(l))\n",
    "            print('i=',i)\n",
    "            print('-------------------------------------------------------------------')\n",
    "        \n",
    "        \n",
    "        # Update x\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Computation time \n",
    "    torch.cuda.synchronize()\n",
    "    print('DONE - total time is '+str(int(time.time()-t))+'s')\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3163a4ac",
   "metadata": {},
   "source": [
    "### Results of Table 1 and Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4cad31e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_917201/1937108815.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mmy_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwgenpatex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblur_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/wgenpatex.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, gaussian_kernel_size, gaussian_std, stride, pad, dim)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaussian_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_downsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaussian_kernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaussian_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/wgenpatex.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, kernel_size, sigma, stride, pad, dim, bias)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgauss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mgaussian_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgauss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgauss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/wgenpatex.py\u001b[0m in \u001b[0;36minit_weights\u001b[0;34m(self, kernel_size, sigma)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minit_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0msemidual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/wgenpatex.py\u001b[0m in \u001b[0;36minit_weights\u001b[0;34m(kernel_size, sigma, dim)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \"\"\"\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mx_cord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mx_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_cord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0my_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# device \n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "# image path \n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/Datasets/18_images_wd_wod_dataset')  \n",
    "\n",
    "list_im_name   = [file for file in glob.glob(\"HR/*.png\")]\n",
    "list_im_modele_with_def   = [file for file in glob.glob(\"HR_with_defects/*.png\")]\n",
    "list_im_modele_without_def   = [file for file in glob.glob(\"HR_without_defects/*.png\")]\n",
    "\n",
    "\n",
    "list_im_name.sort()\n",
    "list_im_modele_with_def.sort()\n",
    "list_im_modele_without_def.sort()\n",
    "list_im_modele=[list_im_modele_with_def,list_im_modele_without_def]\n",
    "\n",
    "# Initialise lists\n",
    "#PSNR [with defects, without defects]\n",
    "list_psnr_ROT=[[],[]]\n",
    "list_psnr_RSUOT=[[],[]]\n",
    "\n",
    "# im_rest\n",
    "list_im_restored_ROT=[[],[]]\n",
    "list_im_restored_RSUOT=[[],[]]\n",
    "\n",
    "# loss\n",
    "list_Loss_ROT=[[],[]]\n",
    "list_Loss_RSUOT=[[],[]]\n",
    "\n",
    "# lr img\n",
    "list_im_LR=[[],[]]\n",
    "\n",
    "# LPIPS\n",
    "list_lpips_ROT=[[],[]]\n",
    "list_lpips_RSUOT=[[],[]]\n",
    "\n",
    "# LPIPS\n",
    "list_ssim_ROT=[[],[]]\n",
    "list_ssim_RSUOT=[[],[]]\n",
    "\n",
    "# Super Resolution\n",
    "\n",
    "# Data attachment \n",
    "lamb=(36/6000)*(600**2/256**2)\n",
    "\n",
    "for i,name_im in enumerate(list_im_name):\n",
    "    for j in range(2):\n",
    "        # set arguments\n",
    "        args=argparse.Namespace()\n",
    "        args.target_image_path=name_im\n",
    "        args.learn_image_path=list_im_modele[j][i]\n",
    "        args.patch_size=6\n",
    "        args.n_patches_out=10000\n",
    "        args.n_patches_in=-1\n",
    "\n",
    "\n",
    "        # Define forward operator\n",
    "        blur_width=2.0\n",
    "        add_boundary=0 # no artificial boundary \n",
    "        kernel_size=16\n",
    "        stride=4\n",
    "        my_layer=wgenpatex.gaussian_layer(kernel_size,blur_width,stride=stride)\n",
    "\n",
    "        def operator(inp):\n",
    "            if add_boundary==0:\n",
    "                return my_layer.forward(inp)\n",
    "            return my_layer.forward(inp[:,:,add_boundary:-add_boundary,add_boundary:-add_boundary])\n",
    "        \n",
    "        # Reproductibility\n",
    "        torch.manual_seed(i)\n",
    "        \n",
    "        # Read HR ground truth\n",
    "        hr_img=wgenpatex.imread(args.target_image_path)\n",
    "        hr_img=tv_resize(256, antialias=True)((0.2989 * hr_img[:,0,:, :] + 0.5870 * hr_img[:,1, :, :] + 0.1140 * hr_img[:,2, :, :]).unsqueeze(1))\n",
    "        \n",
    "        # create (artificially) LR observation\n",
    "        lr_img=wgenpatex.imread(args.target_image_path)\n",
    "        lr_img=tv_resize(256, antialias=True)((0.2989 * lr_img[:,0,:, :] + 0.5870 * lr_img[:,1, :, :] + 0.1140 * lr_img[:,2, :, :]).unsqueeze(1))\n",
    "        args.size=lr_img.shape[2:4]\n",
    "        lr_img_=np.zeros((lr_img.shape[2]+2*add_boundary,lr_img.shape[3]+2*add_boundary))\n",
    "        \n",
    "        if add_boundary>0:\n",
    "            lr_img_[add_boundary:-add_boundary,add_boundary:-add_boundary]=lr_img.squeeze().cpu().numpy()\n",
    "        else:\n",
    "            lr_img_=lr_img.squeeze().cpu().numpy()\n",
    "\n",
    "        lr_img=operator(torch.tensor(lr_img_,dtype=torch.float,device=DEVICE).view(1,1,lr_img_.shape[0],lr_img_.shape[1]))\n",
    "        lr_img+=0.01*torch.randn_like(lr_img)\n",
    "\n",
    "\n",
    "        # build initialization by rescaling the lr observation and extending it to the boundary\n",
    "        upscaled=skimage.transform.resize(lr_img.squeeze().cpu().numpy(),[lr_img.shape[2]*stride,lr_img.shape[3]*stride])\n",
    "        diff=args.size[0]-upscaled.shape[0]\n",
    "\n",
    "        init=np.zeros(args.size,dtype=bool)\n",
    "        init[diff//2:-diff//2,diff//2:-diff//2]=True\n",
    "        grid_x=np.array(range(init.shape[0]))\n",
    "        grid_x=np.tile(grid_x[:,np.newaxis],[1,init.shape[1]])\n",
    "        grid_y=np.array(range(init.shape[1]))\n",
    "        grid_y=np.tile(grid_y[np.newaxis,:],[init.shape[0],1])\n",
    "        points_x=np.reshape(grid_x[init],[-1])\n",
    "        points_y=np.reshape(grid_y[init],[-1])\n",
    "        values=np.reshape(upscaled,[-1])\n",
    "        points=np.stack([points_x,points_y],0).transpose()\n",
    "        init=griddata(points,values,(grid_x,grid_y),method='nearest')\n",
    "        init_=np.random.uniform(size=(init.shape[0]+2*add_boundary,init.shape[1]+2*add_boundary))\n",
    "        if add_boundary==0:\n",
    "            init_=init\n",
    "        else:\n",
    "            init_[add_boundary:-add_boundary,add_boundary:-add_boundary]=init\n",
    "        args.size=init_.shape\n",
    "        \n",
    "        # Read HR reference image \n",
    "        learn_img=wgenpatex.imread(args.learn_image_path)\n",
    "        learn_img=tv_resize(256, antialias=True)((0.2989 * learn_img[:,0,:, :] + 0.5870 * learn_img[:,1, :, :] + 0.1140 * learn_img[:,2, :, :]).unsqueeze(1))\n",
    "        \n",
    "        # Define ROT\n",
    "        def R_OT(x,y,fg_init):\n",
    "            return(ROT(x,y,ε=1e-4,fg_init=fg_init,nb_it=10,dev=DEVICE))\n",
    "    \n",
    "        # Define RSUOT\n",
    "        def RSU_OT(x,y,f_init):\n",
    "            return(RSUOT(x,y,ε=1e-4,ρ=0.01,f_init=f_init,nb_it=10,dev=DEVICE))\n",
    "\n",
    "        # Super resolution with ROT\n",
    "        im_deb_ROT=sinkhorn_super_resolution(operator=operator, high_resolution_image=learn_img,\n",
    "                                                  low_resolution_image=lr_img,init=init_,\n",
    "                                                  loss_fct=R_OT,lbd=lamb, \n",
    "                                                  niters=1, patch_size=6,\n",
    "                                                  n_patches_out=10000,device=DEVICE,verbose=False,lr=0.01)\n",
    "        # Super resolution with RSUOT\n",
    "        im_deb_RSUOT=sinkhorn_super_resolution(operator=operator, high_resolution_image=learn_img,\n",
    "                                                  low_resolution_image=lr_img,init=init_,\n",
    "                                                  loss_fct=RSU_OT,lbd=lamb, \n",
    "                                                  niters=1, patch_size=6,\n",
    "                                                  n_patches_out=10000,device=DEVICE,verbose=False,lr=0.001)\n",
    "\n",
    "        print(\"Etape :\",i)\n",
    "\n",
    "        # Add measures to each list \n",
    "        # PSNR\n",
    "        list_psnr_ROT[j].append(PSNR(torchvision.transforms.CenterCrop(args.size[0]-12)(hr_img.squeeze().to('cpu')),\n",
    "                                torchvision.transforms.CenterCrop(args.size[0]-12)(im_deb_ROT.squeeze().to('cpu'))).item())\n",
    "        list_psnr_RSUOT[j].append(PSNR(torchvision.transforms.CenterCrop(args.size[0]-12)(hr_img.squeeze().to('cpu')),\n",
    "                                torchvision.transforms.CenterCrop(args.size[0]-12)(im_deb_RSUOT.squeeze().to(\"cpu\"))).item())\n",
    "        \n",
    "        # LPIPS\n",
    "        list_lpips_ROT[j].append(loss_fn_alex(torchvision.transforms.CenterCrop(args.size[0]-12)(hr_img.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)\n",
    "                                          , torchvision.transforms.CenterCrop(args.size[0]-12)(im_deb_ROT.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)))\n",
    "        list_lpips_RSUOT[j].append(loss_fn_alex(torchvision.transforms.CenterCrop(args.size[0]-12)(hr_img.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)\n",
    "                                          , torchvision.transforms.CenterCrop(args.size[0]-12)(im_deb_RSUOT.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)))\n",
    "        \n",
    "        # SSIM\n",
    "        img_hr=torchvision.transforms.CenterCrop(args.size[0]-12)(hr_img.squeeze().to('cpu')).detach().numpy()\n",
    "        img_pred_ROT=torchvision.transforms.CenterCrop(args.size[0]-12)(im_deb_ROT.squeeze().to('cpu')).detach().numpy()\n",
    "        img_pred_RSUOT=torchvision.transforms.CenterCrop(args.size[0]-12)(im_deb_RSUOT.squeeze().to('cpu')).detach().numpy()\n",
    "        \n",
    "        list_ssim_ROT[j].append(ssim(img_hr, img_pred_ROT,data_range=img_pred_ROT.max() - img_pred_ROT.min()))\n",
    "        list_ssim_RSUOT[j].append(ssim(img_hr, img_pred_RSUOT,data_range=img_pred_RSUOT.max() - img_pred_RSUOT.min()))\n",
    "        \n",
    "        # Resulting images \n",
    "        list_im_restored_ROT[j].append(im_deb_ROT.clone().to('cpu'))\n",
    "        list_im_restored_RSUOT[j].append(im_deb_RSUOT.clone().to('cpu'))\n",
    "        \n",
    "        # LR images \n",
    "        list_im_LR[j].append(lr_img.clone().to('cpu'))\n",
    "        \n",
    "        # HR images \n",
    "        list_im_HR[j].append(hr_img.clone().to('cpu'))\n",
    "\n",
    "# Save results \n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/Regularised_WPP')\n",
    "\n",
    "# PSNR\n",
    "torch.save(list_psnr_ROT,\"list_psnr_ROT\")\n",
    "torch.save(list_psnr_RSUOT,\"list_psnr_RSUOT\")\n",
    "\n",
    "# LPIPS\n",
    "torch.save(list_lpips_ROT,\"list_lpips_ROT\")\n",
    "torch.save(list_lpips_RSUOT,\"list_lpips_RSUOT\")\n",
    "\n",
    "# SSIM\n",
    "torch.save(list_ssim_ROT,\"list_ssim_ROT\")\n",
    "torch.save(list_ssim_RSUOT,\"list_ssim_RSUOT\")\n",
    "\n",
    "# RESTORED IMAGES\n",
    "torch.save(list_im_restored_ROT,\"list_im_restored_ROT\")\n",
    "torch.save(list_im_restored_RSUOT,\"list_im_restored_RSUOT\")\n",
    "\n",
    "# LR IMAGES\n",
    "torch.save(list_im_LR,\"list_im_LR\")\n",
    "\n",
    "# LR IMAGES\n",
    "torch.save(list_im_LR,\"list_im_HR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e0ecd",
   "metadata": {},
   "source": [
    "### Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add61c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "PSNR_SD=torch.load(\"liste_psnr_SDR10000\")\n",
    "PSNR_E=torch.load(\"liste_psnr_ER10000\")\n",
    "\n",
    "LPIPS_SD=torch.load(\"liste_lpips_SDR10000\")\n",
    "LPIPS_E=torch.load(\"liste_lpips_ER10000\")\n",
    "\n",
    "SSIM_E=torch.load(\"liste_ssim_ER10000\")\n",
    "SSIM_SD=torch.load(\"liste_ssim_SDR10000\")\n",
    "\n",
    "ims_SD=torch.load(\"liste_im_restored_SDR10000\")\n",
    "ims_E=torch.load(\"liste_im_restored_ER10000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800753ef",
   "metadata": {},
   "source": [
    "### Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adecdbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0eaa35f7",
   "metadata": {},
   "source": [
    "### Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c35c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WPP_color",
   "language": "python",
   "name": "wpp_color"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
