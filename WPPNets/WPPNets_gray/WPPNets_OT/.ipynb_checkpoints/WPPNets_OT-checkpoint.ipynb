{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1f918c",
   "metadata": {},
   "source": [
    "# WPPNets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656e527",
   "metadata": {},
   "source": [
    "### Neural network (pre-trained by default) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82a378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Superresolution for the texture tile1\n"
     ]
    }
   ],
   "source": [
    "# This code belongs to the paper\n",
    "#\n",
    "# F. Altekrüger and J. Hertrich. \n",
    "# WPPNets and WPPFlows: The Power of Wasserstein Patch Priors for Superresolution. \n",
    "# ArXiv Preprint#2201.08157\n",
    "#\n",
    "# Please cite the paper, if you use the code.\n",
    "#\n",
    "# The script reproduces the numerical example with the textures 'Floor'\n",
    "# and 'Grass' in the paper.\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage.io as io\n",
    "import model.small_acnet\n",
    "import random\n",
    "import utils\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "torch.cuda.set_device(2)\n",
    "\n",
    "def Downsample(scale = 0.25, gaussian_std = 2):\n",
    "    ''' \n",
    "    downsamples an img by factor 4 using gaussian downsample from utils.py\n",
    "    '''\n",
    "    if scale > 1:\n",
    "        print('Error. Scale factor is larger than 1.')\n",
    "        return\n",
    "    gaussian_std = gaussian_std\n",
    "    kernel_size = 16\n",
    "    gaussian_down = utils.gaussian_downsample(kernel_size,gaussian_std,int(1/scale),pad=True) #gaussian downsample with zero padding\n",
    "    return gaussian_down.to(DEVICE)\n",
    "\n",
    "def WLoss(args, input_img, ref_pat, model, psi):\n",
    "    '''\n",
    "    Computes the proposed wasserstein loss fct consisting of a MSELoss and a Wasserstein regularizer\n",
    "    '''\n",
    "    lam = args.lam\n",
    "    n_patches_out = args.n_patches_out\n",
    "    patch_size = args.patch_size\n",
    "    n_iter_psi = args.n_iter_psi\n",
    "    keops = args.keops\n",
    "    \n",
    "    im2patch = utils.patch_extractor(patch_size,center=args.center)\n",
    "    \n",
    "    num_ref = ref_pat.shape[0] #number of patches of reference image\n",
    "    patch_weights = torch.ones(num_ref,device=DEVICE,dtype=torch.float) #same weight for all patches\n",
    "    \n",
    "    semidual_loss = utils.semidual(ref_pat,usekeops=keops) \n",
    "    semidual_loss.psi.data = psi #update the maximizer psi from previous step\n",
    "    pred = model(input_img) #superresolution of input_img\n",
    "    \n",
    "    #sum up all patches of whole batch\n",
    "    inp_pat = torch.empty(0, device = DEVICE)\n",
    "    for k in range(pred.shape[0]):\n",
    "        inp = im2patch(pred[k,:,:,:].unsqueeze(0)) #use all patches of input_img\n",
    "        inp_pat = torch.cat([inp_pat,inp],0)\n",
    "    inp = inp_pat\n",
    "    \n",
    "    #gradient ascent to find maximizer psi for dual formulation of W2^2\n",
    "    optim_psi = torch.optim.ASGD([semidual_loss.psi], lr=1e-0, alpha=0.5, t0=1)\n",
    "    for i in range(n_iter_psi):\n",
    "        sem = -semidual_loss(inp,patch_weights)\n",
    "        optim_psi.zero_grad()\n",
    "        sem.backward(retain_graph=True)\n",
    "        optim_psi.step()\n",
    "    semidual_loss.psi.data = optim_psi.state[semidual_loss.psi]['ax']\n",
    "    psi = semidual_loss.psi.data #update psi\n",
    "    \n",
    "    reg = semidual_loss(inp,patch_weights) #wasserstein regularizer \n",
    "    \n",
    "    down_pred = operator(pred) #downsample pred by scale_factor\n",
    "\n",
    "    loss_fct = nn.MSELoss()\n",
    "    loss = loss_fct(down_pred,input_img) #||f(G(y)) - y||^2\n",
    "    total_loss = loss + lam * reg\n",
    "    \n",
    "    return [total_loss,loss,lam*reg,psi]\n",
    "\n",
    "\n",
    "def training(trainset, model, reference_img, batch_size, epochs, args, opti):\n",
    "    '''\n",
    "    training process\n",
    "    '''\n",
    "    numb_train_img = trainset.shape[0] #number of all img\n",
    "    \n",
    "    #create random batches:\n",
    "    idx = torch.randperm(numb_train_img)\n",
    "    batch_lr = [] #list of batches\n",
    "    for i in range(0,numb_train_img,batch_size):\n",
    "        batch_lr.append(trainset[i:(i+batch_size),...])\n",
    "    \n",
    "    #create maximizer psi\n",
    "    psi_length = args.n_patches_out #length of vector psi\n",
    "    psi_list = []\n",
    "    for i in range(len(batch_lr)):\n",
    "        psi_list.append(torch.zeros(psi_length, device = DEVICE)) #create a list consisting of psi\n",
    "\n",
    "    #create random patches of reference image\n",
    "    im2patch = utils.patch_extractor(args.patch_size,center=args.center)\n",
    "    ref = im2patch(reference_img,args.n_patches_out)\n",
    "    \n",
    "    a_psnr_list = [] #for validation\n",
    "    loss_list = []; reg_list = []; MSE_list = [] #for plot\n",
    "\n",
    "    for t in tqdm(range(epochs)):\n",
    "        a_totalloss = 0; a_MSE = 0; a_reg = 0\n",
    "        ints = random.sample(range(0,len(batch_lr)),len(batch_lr)) #random order of batches\n",
    "        for i in tqdm(ints):\n",
    "            psi_temp = psi_list[i] #choose corresponding saved maximizer psi  \n",
    "            [total_loss,loss,reg,p] = WLoss(args, batch_lr[i], ref, model, psi_temp)  \n",
    "    \n",
    "            #backpropagation\n",
    "            opti.zero_grad()\n",
    "            total_loss.backward()\n",
    "            opti.step()\n",
    "            \n",
    "            total_loss = total_loss.item(); loss = loss.item(); reg = reg.item()\n",
    "            a_totalloss += total_loss; a_MSE += loss; a_reg += reg\n",
    "            psi_list[i] = p #update psi\n",
    "\n",
    "        a_totalloss = a_totalloss/len(batch_lr); a_MSE = a_MSE/len(batch_lr); a_reg = a_reg/len(batch_lr)\n",
    "        loss_list.append(a_totalloss); MSE_list.append(a_MSE); reg_list.append(a_reg)\n",
    "        \n",
    "        if not os.path.isdir('checkpoints'):\n",
    "            os.mkdir('checkpoints')\n",
    "        \n",
    "        val_step = 10\n",
    "        if (t+1)%val_step == 0:\n",
    "            print(f'------------------------------- \\nValidation step')\n",
    "            val_len = len(args.val)\n",
    "            a_psnr = 0\n",
    "            for i in range(val_len):\n",
    "                with torch.no_grad():\n",
    "                    pred = net(args.val[i][0])\n",
    "                psnr_val = utils.psnr(pred,args.val[i][1],40)\n",
    "                a_psnr += psnr_val\n",
    "            a_psnr = a_psnr / val_len\n",
    "            print(f'Average Validation PSNR: {a_psnr}')    \n",
    "            a_psnr_list.append(a_psnr)\n",
    "            plt.plot(list(range(val_step,val_step*len(a_psnr_list)+val_step,val_step)),a_psnr_list, 'k')\n",
    "            title = 'Avarage PSNR ' + str(round(a_psnr,2))\n",
    "            plt.title(title)\n",
    "            plt.savefig('checkpoints/ValidatonPSNR_'+image_class+'.pdf')\n",
    "            plt.close()\n",
    "            print(f'-------------------------------')\n",
    "        \n",
    "        #save a checkpoint\n",
    "        if (t+1)%30 == 0:\n",
    "            torch.save({'net_state_dict': model.state_dict()}, 'checkpoints/checkpoint_'+image_class+'.pth')\n",
    "            with torch.no_grad():\n",
    "                pred_hr = model(lr)\n",
    "            if not os.path.isdir('checkpoints/tmp'):\n",
    "                os.mkdir('checkpoints/tmp')\n",
    "            utils.save_img(pred_hr,'checkpoints/tmp/pred'+str(t+1))\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.plot(list(range(len(loss_list))), loss_list, 'k-.', label='avarage loss')\n",
    "            plt.plot(list(range(len(MSE_list))), MSE_list, 'k-', label='avarage MSE')\n",
    "            plt.plot(list(range(len(reg_list))), reg_list, 'k:', label='avarage Reg')\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.yscale('log')\n",
    "            plt.savefig('checkpoints/losscurve_'+image_class+'.pdf')\n",
    "            plt.close()\n",
    "\n",
    "retrain = False\n",
    "if __name__ == '__main__':\n",
    "    if not os.path.isdir('results'):\n",
    "       os.mkdir('results')    \n",
    "    \n",
    "    net = model.small_acnet.Net(scale=4).to(device=DEVICE)\n",
    "    image_classes = ['tile1','wood1']  \n",
    "    image_class = image_classes[0] #choose the texture\n",
    "    print('Superresolution for the texture ' + image_class)\n",
    "    \n",
    "    hr = utils.imread('test_img/hr_'+image_class+'.png')\n",
    "    lr = utils.imread('test_img/lr_'+image_class+'.png')\n",
    "    #  = operator(hr) + 0.01*torch.randn_like(operator(hr))\n",
    "    if retrain:\n",
    "        #inputs\n",
    "        lr_train = utils.Trainset(image_class = image_class, size = 1000)\n",
    "        val = utils.Validationset(image_class = image_class)\t\n",
    "        lr_size = lr_train.shape[2]\n",
    "        operator = Downsample(scale = 1/4, gaussian_std = 2)\n",
    "\n",
    "        args=argparse.Namespace()\n",
    "        args.lam=12.5/lr_size**2\n",
    "        args.n_patches_out=10000\n",
    "        args.patch_size=6\n",
    "        args.val = val\n",
    "        args.keops = True\n",
    "\n",
    "        if image_class == 'tile1':\n",
    "            args.center = True\n",
    "            epochs = 5\n",
    "            args.n_iter_psi=20\n",
    "        elif image_class == 'wood1':\n",
    "            args.center = True\n",
    "            epochs = 270\n",
    "            args.n_iter_psi=20\n",
    "\n",
    "        reference_img = utils.imread('test_img/ref_'+image_class+'.png')        \n",
    "        \n",
    "        #training process\n",
    "        batch_size = 25\n",
    "        learning_rate = 1e-4\n",
    "        OPTIMIZER = torch.optim.Adam(net.parameters(), lr=learning_rate)    \n",
    "        \n",
    "        training(lr_train,net,reference_img,batch_size,epochs,args=args,opti=OPTIMIZER)\n",
    "        with torch.no_grad():\n",
    "            pred = net(lr)\n",
    "        torch.save({'net_state_dict': net.state_dict(), 'optimizer_state_dict': OPTIMIZER.state_dict()},\n",
    "                    'results/weights_'+image_class+'.pth')        \n",
    "        utils.save_img(pred,'results/W2_'+image_class)\n",
    "            \n",
    "    if not retrain:\n",
    "        weights = torch.load('results/weights_'+image_class+'.pth',map_location=DEVICE)\n",
    "        net.load_state_dict(weights['net_state_dict'])\n",
    "        pred = net(lr)\n",
    "        utils.save_img(pred,'results/W2_'+image_class)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c305a3",
   "metadata": {},
   "source": [
    "### Average PSNR/SSIM/LPIPS scores obtained on the test set TILE or WOOD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1e0752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/prof/smignon/anaconda3/envs/WPPNets/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n",
      "DONE - total time is 0.013933658599853516s\n",
      "DONE - total time is 0.012628555297851562s\n",
      "DONE - total time is 0.013883352279663086s\n",
      "DONE - total time is 0.013358831405639648s\n",
      "DONE - total time is 0.012743949890136719s\n",
      "DONE - total time is 0.012645244598388672s\n",
      "DONE - total time is 0.012791156768798828s\n",
      "DONE - total time is 0.012664318084716797s\n",
      "DONE - total time is 0.01267385482788086s\n",
      "DONE - total time is 0.012616157531738281s\n",
      "DONE - total time is 0.012576103210449219s\n",
      "DONE - total time is 0.012459278106689453s\n",
      "DONE - total time is 0.013438940048217773s\n",
      "DONE - total time is 0.012555599212646484s\n",
      "DONE - total time is 0.012616872787475586s\n",
      "DONE - total time is 0.012808799743652344s\n",
      "DONE - total time is 0.012719869613647461s\n",
      "DONE - total time is 0.012708187103271484s\n",
      "DONE - total time is 0.012525081634521484s\n",
      "tensor(31.9918)\n",
      "tensor(0.1804)\n",
      "0.5307099675578439\n"
     ]
    }
   ],
   "source": [
    "# PSNR, LPIPS, SSIM, Blur Effect moyen sur une base d'images constitué d'un seul type de textures WOOD1:\n",
    "import numpy as np\n",
    "import glob\n",
    "from skimage import (color, data, measure)\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import lpips\n",
    "import torchvision\n",
    "\n",
    "# Choose your image class \n",
    "image_class=\"wood\"\n",
    "#image_class=\"tile\"\n",
    "\n",
    "def PSNR(im,im_new):\n",
    "    M,N=im_new.shape\n",
    "    EQM=1/(M*N)*torch.sum((im-im_new)**2)\n",
    "    psnr=10*torch.log10(1/EQM)\n",
    "    return(psnr)\n",
    "\n",
    "loss_fn_alex = lpips.LPIPS(net='alex') # best forward scores\n",
    "\n",
    "# emplacement des images \n",
    "liste_im_name_HR   = [file for file in glob.glob(\"test_img/test_img_WPPNets/\"+image_class+\"/HR/*.png\")]#.sort()\n",
    "liste_im_name_LR   = [file for file in glob.glob(\"test_img/test_img_WPPNets/\"+image_class+\"/LR/*.png\")]#.sort()\n",
    "\n",
    "liste_im_name_HR.sort()\n",
    "liste_im_name_LR.sort()\n",
    "\n",
    "# listes pour enregistrer PSNR, LPIPS, SSIM, Blur Effect \n",
    "PSNRs=[]\n",
    "LPIPS=[]\n",
    "SSIM=[]\n",
    "Blue_Effect=[]\n",
    "PRED=[]\n",
    "\n",
    "# Chargement du bon NN\n",
    "weights = torch.load('results/weights_'+image_class+'1.pth',map_location=DEVICE) \n",
    "weights = torch.load('results/weights_'+image_class+'1.pth',map_location=DEVICE) \n",
    "net.load_state_dict(weights['net_state_dict'])\n",
    "\n",
    "L_t=[]\n",
    "for i,name_im in enumerate(liste_im_name_HR):\n",
    "    \n",
    "    hr = utils.imread(liste_im_name_HR[i])\n",
    "    lr = utils.imread(liste_im_name_LR[i])\n",
    "    \n",
    "    # Temps de calcul \n",
    "    torch.cuda.synchronize()\n",
    "    t = time.time()\n",
    "    \n",
    "    pred = net(lr)\n",
    "    \n",
    "    # Computation time \n",
    "    torch.cuda.synchronize()\n",
    "    temps=time.time()-t\n",
    "    print('DONE - total time is '+str(temps)+'s')\n",
    "    L_t.append(temps)\n",
    "    \n",
    "    # LPIPS\n",
    "    LPIPS.append(loss_fn_alex(torchvision.transforms.CenterCrop(600-12)(hr.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)\n",
    "                                      , torchvision.transforms.CenterCrop(600-12)(pred.squeeze().to('cpu')).unsqueeze(0).unsqueeze(0)))\n",
    "    # PSNR\n",
    "    PSNRs.append(PSNR(torchvision.transforms.CenterCrop(600-12)(hr.squeeze().to('cpu')),\n",
    "                            torchvision.transforms.CenterCrop(600-12)(pred.squeeze().to('cpu'))))\n",
    "    \n",
    "    # SSIM\n",
    "    img_hr= torchvision.transforms.CenterCrop(600-12)(hr.squeeze().to('cpu')).detach().numpy()\n",
    "    img_pred= torchvision.transforms.CenterCrop(600-12)(pred.squeeze().to('cpu')).detach().numpy()\n",
    "    SSIM.append(ssim(img_hr, img_pred,data_range=img_pred.max() - img_pred.min()))\n",
    "    \n",
    "    # im pred \n",
    "    PRED.append(pred)\n",
    "    \n",
    "# Moyenne des valeurs sur le jeu de données\n",
    "print(torch.mean(torch.tensor(PSNRs)))\n",
    "print(torch.mean(torch.tensor(LPIPS)))\n",
    "print(np.mean(SSIM))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WPPNets",
   "language": "python",
   "name": "wppnets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
