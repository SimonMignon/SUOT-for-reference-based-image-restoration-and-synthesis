{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de43dfc",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff5ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pykeops.torch import LazyTensor\n",
    "import numpy as np\n",
    "from torchvision.transforms import Resize as tv_resize\n",
    "from PIL import Image\n",
    "import time\n",
    "from IPython.display import display\n",
    "from torch import nn\n",
    "import math\n",
    "import skimage.io as io\n",
    "import os\n",
    "import skimage.metrics as sm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import lpips\n",
    "import torchvision\n",
    "from OT_SUOT import OT,SUOT\n",
    "import cv2\n",
    "from torchvision.utils import save_image\n",
    "from os.path import join\n",
    "\n",
    "from utils import interpolate_shift_map, get_pyramid\n",
    "from patchmatch import patch_match\n",
    "from reconstruct import reconstruct\n",
    "from initialisation import initialisation, initialisation_from_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9adda0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "  \n",
    "# Prints the list of directories that the \n",
    "# interpreter will search for the required module. \n",
    "print(sys.path)\n",
    "\n",
    "sys.path.insert(0, \"/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331c89f3",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(tensor_img, name):\n",
    "\t'''\n",
    "\tsave img (tensor form) with the name\n",
    "\t'''\n",
    "\timg = np.clip(tensor_img.squeeze().detach().cpu().numpy(),0,1)\n",
    "\tio.imsave(str(name)+'.png', img)\n",
    "\treturn     \n",
    "\n",
    "def imread(img_name):\n",
    "    '''\n",
    "    loads an image as torch.tensor on the selected device\n",
    "    '''\n",
    "    np_img = io.imread(img_name)\n",
    "    tens_img = torch.tensor(np_img, dtype=torch.float, device=DEVICE)\n",
    "    if torch.max(tens_img) > 1:\n",
    "        tens_img/=255 \t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    if len(tens_img.shape) < 3:\n",
    "        tens_img = tens_img.unsqueeze(2)\t\t\t\t\t\t\n",
    "    if tens_img.shape[2] > 3:\t\t\t\t\t\t\t\t\t\t\n",
    "        tens_img = tens_img[:,:,:3]\n",
    "    tens_img = tens_img.permute(2,0,1)\t\n",
    "    return tens_img.unsqueeze(0)\t\n",
    "\n",
    "def show(im_deb,col=False):\n",
    "    im_deb=im_deb.clone().detach()\n",
    "    im_deb[im_deb>1]=1\n",
    "    im_deb[im_deb<0]=0\n",
    "    if col==True:\n",
    "        im_deb=(255*im_deb.permute(1, 2, 0)).type(dtype=torch.uint8)\n",
    "    else:\n",
    "        im_deb=(255*im_deb).type(dtype=torch.uint8)\n",
    "    imgpil = Image.fromarray(im_deb.numpy()) \n",
    "    display(imgpil)\n",
    "    \n",
    "class patch_extractor(nn.Module):\n",
    "    '''\n",
    "    Module for creating custom patch extractor\n",
    "    '''\n",
    "    def __init__(self, patch_size, pad=False,center=False):\n",
    "        super(patch_extractor, self).__init__()\n",
    "        self.im2pat = nn.Unfold(kernel_size=patch_size)\n",
    "        self.pad = pad\n",
    "        self.padsize = patch_size-1\n",
    "        self.center=center\n",
    "        self.patch_size=patch_size\n",
    "\n",
    "    def forward(self, input, batch_size=0):\n",
    "        if self.pad:\n",
    "            input = torch.cat((input, input[:,:,:self.padsize,:]), 2)\n",
    "            input = torch.cat((input, input[:,:,:,:self.padsize]), 3)\n",
    "        patches = self.im2pat(input).squeeze(0).transpose(1,0)\n",
    "        if batch_size > 0:\n",
    "            idx = torch.randperm(patches.size(0))[:batch_size]\n",
    "            patches = patches[idx,:]\n",
    "        if self.center:\n",
    "            patches = patches - torch.mean(patches,-1).unsqueeze(-1)\n",
    "        return patches\n",
    "\n",
    "def gradient_flow(init_img,hr_img,function_OT,n_iter,verbose=False,patch_size=6):\n",
    "    \n",
    "    # patchs exctractors\n",
    "    target_im2pat = patch_extractor(patch_size, pad=False,center=False)\n",
    "    input_im2pat = patch_extractor(patch_size, pad=False,center=False)\n",
    "    \n",
    "    # load y patches\n",
    "    y= hr_img.clone()\n",
    "    nuY = target_im2pat(y, -1).contiguous()\n",
    "    \n",
    "    # load x\n",
    "    x=init_img.clone()\n",
    "    _,_,N,M=x.shape\n",
    "    x.requires_grad = True\n",
    "    \n",
    "    # init g\n",
    "    g_i=None\n",
    "    \n",
    "    # optimizer \n",
    "    optimizer = torch.optim.Adam([x], lr=0.01)\n",
    "    \n",
    "    # Temps de calcul \n",
    "    torch.cuda.synchronize()\n",
    "    t = time.time()\n",
    "    for i in range(n_iter):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Exctract x patches \n",
    "        nuX = input_im2pat(x, -1).contiguous()\n",
    "        \n",
    "        # Compute loss\n",
    "        if i==0:\n",
    "            OT_cost,g_i = function_OT(nuX,nuY,g_i,10000)\n",
    "        if i!=0:\n",
    "            OT_cost,g_i = function_OT(nuX,nuY,g_i,10)\n",
    "        \n",
    "        if verbose==True:\n",
    "            print('n=',i,', OT: ',OT_cost.clone().item())\n",
    "        \n",
    "        # Compute the gradient\n",
    "        OT_cost.backward()\n",
    "        \n",
    "        # Update x\n",
    "        optimizer.step()\n",
    "    torch.cuda.synchronize()\n",
    "    temps=int(time.time()-t)\n",
    "    print('DONE - total time is '+str(temps)+'s')\n",
    "    \n",
    "    return x,temps\n",
    "\n",
    "###### Psin ######\n",
    "\n",
    "def get_texture(img):\n",
    "    \"\"\"Compute the texture features (gradients).\n",
    "    Only the magnitude of the gradient in each direction is kept (|gx|, |gy|).\n",
    "    returns: (H, W, 2)\n",
    "    \"\"\"\n",
    "    grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gy, gx = np.gradient(grayscale)\n",
    "\n",
    "    gx = np.abs(gx)\n",
    "    gy = np.abs(gy)\n",
    "\n",
    "    return np.stack((gy, gx), axis=-1)\n",
    "\n",
    "def scale(src, init=None, nb_levels=2, output=\".\"):\n",
    "    print(\"Computing features and pyramid...\", end=\" \", flush=True)\n",
    "    if USE_TEXTURE:\n",
    "        texture = get_texture(src)\n",
    "        src = np.concatenate((src, BETA * texture), axis=-1)\n",
    "    src_pyramid = get_pyramid(src, nb_levels=nb_levels)\n",
    "    print(\"Done\")\n",
    "\n",
    "    patch_match_params = {\n",
    "        \"n_iters\": 10,\n",
    "        \"alpha\": 0.5,\n",
    "        \"w\": max(src.shape[:2]),\n",
    "    }\n",
    "\n",
    "    print(\"Initialisation...\", end=\" \", flush=True)\n",
    "    if init is not None:\n",
    "        img, shift_map = initialisation_from_img(src_pyramid[-1], init, patch_match_params)\n",
    "    else:\n",
    "        img, shift_map = initialisation(src_pyramid[-1], patch_match_params)\n",
    "    print(\"Done\")\n",
    "\n",
    "    for level in reversed(range(nb_levels)):\n",
    "        print(f\"Level {level}...\", end=\" \", flush=True)\n",
    "        src = src_pyramid[level]\n",
    "\n",
    "        # Interpolate the shift volume and reconstruct at this level\n",
    "        if level != (nb_levels - 1):\n",
    "            shift_map = interpolate_shift_map(shift_map, src.shape)\n",
    "            img = reconstruct(src, shift_map, method=\"weighted\")\n",
    "\n",
    "        print(\"Done\")\n",
    "        cv2.imwrite(join(output, f\"iter_{level}.png\"), img[..., :3] * 255)\n",
    "        \n",
    "def generate(src, init=None, nb_levels=3, output=\".\"):\n",
    "    print(\"Computing features and pyramid...\", end=\" \", flush=True)\n",
    "    if USE_TEXTURE:\n",
    "        texture = get_texture(src)\n",
    "        src = np.concatenate((src, BETA * texture), axis=-1)\n",
    "    src_pyramid = get_pyramid(src, nb_levels=nb_levels)\n",
    "    print(\"Done\")\n",
    "\n",
    "    patch_match_params = {\n",
    "        \"n_iters\": 10,\n",
    "        \"alpha\": 0.5,\n",
    "        \"w\": max(src.shape[:2]),\n",
    "    }\n",
    "\n",
    "    print(\"Initialisation...\", end=\" \", flush=True)\n",
    "    if init is not None:\n",
    "        img, shift_map = initialisation_from_img(src_pyramid[-1], init, patch_match_params)\n",
    "    else:\n",
    "        img, shift_map = initialisation(src_pyramid[-1], patch_match_params)\n",
    "    print(\"Done\")\n",
    "\n",
    "    for level in reversed(range(nb_levels)):\n",
    "        print(f\"Level {level}...\", end=\" \", flush=True)\n",
    "        src = src_pyramid[level]\n",
    "\n",
    "        # Interpolate the shift volume and reconstruct at this level\n",
    "        if level != (nb_levels - 1):\n",
    "            shift_map = interpolate_shift_map(shift_map, src.shape)\n",
    "            img = reconstruct(src, shift_map, method=\"weighted\")\n",
    "\n",
    "        iteration_nb = 1\n",
    "        residual = float(\"inf\")\n",
    "        while iteration_nb <= MAX_ITER and residual > RESIDUAL_THRESH:\n",
    "            previous_img = img.copy()\n",
    "\n",
    "            shift_map = patch_match(img, src, shift_map, patch_match_params)\n",
    "            img = reconstruct(src, shift_map, method=\"weighted\")\n",
    "\n",
    "            iteration_nb += 1\n",
    "            residual = np.mean(np.abs(img - previous_img))\n",
    "\n",
    "        print(\"Done\")\n",
    "        cv2.imwrite(join(output, f\"iter_{level}.png\"), img[..., :3] * 255)\n",
    "        \n",
    "### Diversity score from a list L of generated images ###\n",
    "\n",
    "def DIVERSITY(L,ref_img):\n",
    "    # Liste synthèse images \n",
    "    I=torch.stack([0.299*im[0,:,:]+0.587*im[1,:,:]+0.114*im[2,:,:] for im in L])\n",
    "    I_mu=torch.mean(I,0)\n",
    "    std_ij=torch.sqrt(torch.mean((I-I_mu)**2,0))\n",
    "    std_bar=torch.mean(std_ij)\n",
    "    #print(std_bar)\n",
    "    \n",
    "    # Image de référence \n",
    "    I_ref=0.299*ref_img[0,:,:]+0.587*ref_img[1,:,:]+0.114*ref_img[2,:,:]\n",
    "    #I_ref=ref_img\n",
    "    I_mu_ref=torch.mean(I_ref)\n",
    "    std_ref=torch.sqrt(torch.mean((I_ref-I_mu_ref)**2))\n",
    "    #print(std_ref)\n",
    "    return std_bar/std_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee442fa5",
   "metadata": {},
   "source": [
    "### Table 5, Figure 9 (Diversity scores only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0466cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "# \n",
    "os.chdir('/home/prof/smignon/ot_patch_denoising/Wasserstein_Patch_Prior/GitHub_SIAM/Datasets/Psin_reference_images')  \n",
    "LIST_IMG_REF=['38.jpg','birds2.jpg','41.jpg']\n",
    "DIVERSITY_LIST=[]\n",
    "L_tot=[]\n",
    "\n",
    "for i in range(3):\n",
    "    LIST_IMG=[]\n",
    "    for k in range(50):\n",
    "        print('i=',i,', k=',k)\n",
    "        torch.manual_seed(k)\n",
    "\n",
    "        if __name__ == '__main__':\n",
    "            # Reference image path \n",
    "            path_target_image=LIST_IMG_REF[i]\n",
    "            PatchSize=11\n",
    "\n",
    "            # Define OT/SUOT\n",
    "            def B_OT(x,y,g_init,n):\n",
    "                return(OT(x,y,g_init=g_init,nb_it=n,dev=DEVICE,lr=1))\n",
    "            \n",
    "            def SU_OT(x,y,g_init,n):\n",
    "                return(SUOT(x,y,g_init=g_init,nb_it=n,ρ=0.01,dev=DEVICE,lr=0.1))\n",
    "            \n",
    "            Used_OT=SU_OT # choose your used OT\n",
    "\n",
    "            # reference image pymamid scale \n",
    "            src = cv2.imread(path_target_image).astype(np.float32) / 255.0\n",
    "            src_pyramid = get_pyramid(src, nb_levels=4)\n",
    "\n",
    "            # save scale 1/8 and 1/4\n",
    "            cv2.imwrite(\"src_scale_1_8.png\", src_pyramid[3][..., :3] * 255)\n",
    "            cv2.imwrite(\"src_scale_1_4.png\", src_pyramid[2][..., :3] * 255)\n",
    "\n",
    "            # INIT OT: gradient_flow scale 1/8\n",
    "            ref_img = imread(\"src_scale_1_8.png\") # load reference image scale 1/8\n",
    "\n",
    "            # INITIALISATION IMAGE\n",
    "            init_img =torch.randn_like(ref_img)+0.5 # Initialise gradient_flow with N(0.5,1)\n",
    "\n",
    "            new_images,temps=gradient_flow(init_img=init_img,hr_img=ref_img,function_OT=Used_OT,n_iter=1000,verbose=False,patch_size=PatchSize)\n",
    "            show(new_images.clone().detach().squeeze().to('cpu'),col=True)\n",
    "\n",
    "            # 1/8 to 1/4: Upscale using scale()\n",
    "            ref_img = cv2.imread(\"src_scale_1_4.png\").astype(np.float32) / 255.0 # chargement de l'image de référence à l'échelle 1/8\n",
    "            save_image(new_images,\"init_1_8.png\") # Enregistrement de l'image obtenue avec OT\n",
    "            img_init = cv2.imread(\"init_1_8.png\").astype(np.float32) / 255.0 # Chargement pour Psin\n",
    "\n",
    "            scale(ref_img, init=img_init, nb_levels=2) # save in iter_0.png\n",
    "\n",
    "            # INIT OT: gradient_flow scale 1/4\n",
    "            ref_img=imread(\"src_scale_1_4.png\")\n",
    "            show(ref_img.clone().detach().squeeze().to('cpu'),col=True)\n",
    "            init_img =imread(\"iter_0.png\")\n",
    "            show(init_img.clone().detach().squeeze().to('cpu'),col=True)\n",
    "\n",
    "            new_images,temps=gradient_flow(init_img=init_img,hr_img=ref_img,function_OT=Used_OT,n_iter=1000,verbose=False,patch_size=PatchSize)\n",
    "            show(new_images.clone().detach().squeeze().to('cpu'),col=True)\n",
    "\n",
    "            # 1/4 to 1: Last scales with Psin (generate())\n",
    "            # Psin 1/4 --> 1/2 --> 1\n",
    "\n",
    "            save_image(new_images,\"init_1_4.png\")#, normalize=True)\n",
    "            img_init = cv2.imread(\"init_1_4.png\").astype(np.float32) / 255.0\n",
    "            #img_init = cv2.cvtColor(img_init, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "\n",
    "            generate(src, init=img_init, nb_levels=3)\n",
    "\n",
    "            # Enregistrement de la liste d'image pour calculer la diversité \n",
    "            synth_img=imread(\"iter_0.png\")\n",
    "            LIST_IMG.append(synth_img.squeeze())\n",
    "            L_tot.append(synth_img.squeeze())\n",
    "\n",
    "    # DIVERSITY\n",
    "    ref_img=imread(path_target_image).squeeze()\n",
    "    DIVERSITY_LIST.append(DIVERSITY(LIST_IMG,ref_img))\n",
    "\n",
    "torch.save(L_tot,\"list_im_synth_OT\")\n",
    "torch.save(DIVERSITY_LIST,\"list_diversity_OT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WPP_color",
   "language": "python",
   "name": "wpp_color"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
